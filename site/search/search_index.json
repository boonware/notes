{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"axiomatic_set_theory/axiomatic_systems_and_proofs/","title":"Axiomatic systems and proofs","text":""},{"location":"axiomatic_set_theory/axiomatic_systems_and_proofs/#axiomatic-systems-proofs","title":"Axiomatic Systems &amp; Proofs","text":""},{"location":"axiomatic_set_theory/logic/","title":"Logic","text":""},{"location":"axiomatic_set_theory/logic/#propositional-logic","title":"Propositional Logic","text":"<p>A propostion \\(p\\) is a variable that can be either true or false. It is not the goal of propositional logic to determine if a given proposition is true or false, but rather only to determine the consequences from given propositions using logical operators.</p> <p>We use logical operators to create new propositions from existing ones. In the sections below some of these operators are shown. Note that symbol used for an operator may vary.</p>"},{"location":"axiomatic_set_theory/logic/#unary-operators","title":"Unary Operators","text":"\\(p\\) \\(id. \\ p\\) (identity) \\(\\neg p\\) (not) \\(\\top p\\) (tautology) \\(\\bot p\\) (contradiction) \\(t\\) \\(t\\) \\(f\\) \\(t\\) \\(f\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\) \\(f\\)"},{"location":"axiomatic_set_theory/logic/#binary-operators","title":"Binary Operators","text":"<p>In total there are \\(2^4\\) binary logical operators, the most important of which are shown below. The predicate \\(p\\) is known as the \"antecendent\" and \\(q\\) as the \"consequent\".</p> \\(p\\) \\(q\\) \\(p \\land q\\) (and) \\(p \\lor q\\) (or) \\(p \\veebar q\\) (xor) \\(p \\implies q\\) (implication) \\(p \\iff q\\) (equivalence) \\(t\\) \\(t\\) \\(t\\) \\(t\\) \\(f\\) \\(t\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(f\\) \\(t\\) \\(f\\) \\(t\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(f\\) \\(f\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\)"},{"location":"axiomatic_set_theory/logic/#material-implication","title":"Material Implication","text":"<p>The implication operator \\(p \\implies q\\) is also known as \"material implication\". The usage of \"material\" here was used historically to highlight that the relationship between \\(p\\) and \\(q\\) is not causal, in contrast with  \"formal implication\" where \"... the presence of a certain formal connection between antecedent and consequent is an indispensable condition of the meaningfulness and truth of the implication\" (Tarski).</p> <p>In everyday language \"implies\" often comes with the notion of causality. The material implication \\(p \\implies q\\) is not about causality; one must remember that it is simply an operator between two predicates and says nothing about whether they are causally connected. The usefulness of the operator is that we can use it to communicate an assertion, but of course we must still separately show or prove the assertion. For example, if I wish to prove some mathematical theorem \\(b\\) and I believe that proving some predicate \\(a\\) will show that \\(b\\) is true then I can write \\(a \\implies b\\) to communicate this assertion but I still need to write the proof for \\(a\\) and show why it also proves \\(b\\).</p> <p>We may also consider why the material implication takes the values that is does. In the following, we consider a \"logically possible universe\" as any universe that could exist without contradictions, for example, a universe where a circle has four corners is not logically possible.</p> <ul> <li>\\(t \\implies t\\) - In all logically possible universes a truth can only imply or cause another truth. As the antecedent is true it is restricted by reality and can only imply other truths, so this implication evaluates to true.</li> <li>\\(t \\implies f\\) - In no logically possible universe could a truth imply a falsehood for the same reason above, so this implication evaluates to false.</li> <li>\\(f \\implies t\\) - In all logically possible universes a falsehood can imply a truth. Since the antecedent is false it is not rooted in or restricted by reality so it can imply anything you want it to! This implication evaluates to true.</li> <li>\\(f \\implies f\\) - In all logically possible universes a falsehood can imply a falsehood for the same reason that it can imply a truth. This implication evaluates to true.</li> </ul>"},{"location":"axiomatic_set_theory/logic/#theorem-proof-by-contradiction","title":"Theorem: Proof by Contradiction","text":"<p>Any assertion can be proven by way of contradiction:</p> \\[     (p \\implies q) \\iff (\\neg q \\implies \\neg p) \\]"},{"location":"axiomatic_set_theory/logic/#proof","title":"Proof","text":"\\(p\\) \\(q\\) \\(\\neg p\\) \\(\\neg q\\) \\(p \\implies q\\) \\(\\neg q \\implies \\neg p\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(t\\) \\(f\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\) \\(f\\) \\(f\\) \\(f\\) \\(f\\) \\(f\\) \\(t\\) \\(t\\) \\(t\\) \\(t\\) <p>The columns for \\((p \\implies q)\\) and \\((\\neg q \\implies \\neg p)\\)  are identical.</p>"},{"location":"axiomatic_set_theory/logic/#predicate-logic","title":"Predicate Logic","text":"<p>A predicate is a proposition-valued function of some variable(s).</p> <p>New predicates can be constructed from others, for example:</p> \\[     Q(x, y, z): \\iff P(x) \\land R(y, z) \\]"},{"location":"axiomatic_set_theory/logic/#quantifiers","title":"Quantifiers","text":"<p>New predicates can also be constructed using what are called quantifiers.</p> <p>\"For all \\(x\\), \\(P(x)\\)\" is written as:</p> <p>$ \\forall x : P(x)$</p> <p>\"There exists an \\(x\\) such that \\(P(x)\\)\" is defined as:</p> <p>$ \\exists x : P(x) \\iff \\neg (\\forall x : \\neg P(x))$</p> <p>\"There exists a unique \\(x\\) such that \\(P(x)\\)\" is defined as:</p> <p>$ \\exists! x : P(x) \\iff (\\exists x : P(x)) \\land (\\neg \\exists y : P(y) \\land y \\neq x)$ </p>"},{"location":"axiomatic_set_theory/zermelo_fraenkel_axioms/","title":"Zermelo-Fraenkel Axioms","text":""},{"location":"axiomatic_set_theory/zermelo_fraenkel_axioms/#1-axiom-of-the-epsilon-relation","title":"1. Axiom of the \\(\\epsilon\\)-Relation","text":""},{"location":"complex_analysis/complex_numbers/","title":"Complex numbers","text":""},{"location":"complex_analysis/complex_numbers/#complex-numbers","title":"Complex Numbers","text":""},{"location":"complex_analysis/complex_numbers/#definition","title":"Definition","text":"\\[     i = \\sqrt{-1} \\] \\[     z = a  + ib \\quad a,b \\in \\mathbb{R} \\quad z \\in \\mathbb{C} \\] <p>The real and imaginary parts can be identified as follows:</p> \\[     Re(z) = a \\quad Im(z) = b \\] <p>The complex conjugate (\"z star\") is defined as follows:</p> \\[     z^* = a - ib \\]"},{"location":"complex_analysis/complex_numbers/#norm","title":"Norm","text":"<p>A complex number can be pictured as representing a point in a plane, with the real and imaginary parts representing the orthogonal coordinates. The norm is then given by the length of the line from the origin to the point in the plane:</p> \\[     |z| = \\sqrt{a^2 + b^2} \\] \\[     zz^* = |z|^2 \\]"},{"location":"complex_analysis/complex_numbers/#multiplication","title":"Multiplication","text":"<p>Multiplication of complex numbers proceeds like any other product of bracketed expressions:</p> \\[     (a+ib)(c+id) = ac + iad + ibc - bd \\]"},{"location":"complex_analysis/complex_numbers/#division","title":"Division","text":"<p>Dividing complex numbers can be achieved by multiplying above and below by the complex conjugate of the denominator:</p> \\[     \\frac{a+ib}{c+id} = \\left( \\frac{a+ib}{c+id} \\right) \\left( \\frac{c-id}{c-id} \\right) \\]"},{"location":"complex_analysis/complex_numbers/#polar-form","title":"Polar Form","text":"<p>Considering the complex number \\(z\\) as a point in a two-dimensional plane, we can write \\(z\\) in polar form using the angle \\(\\theta\\) between the line from the origin of length \\(|z|\\) and the real axis:</p> \\[     z = |z| \\left( \\cos{\\theta} + i\\sin{\\theta} \\right) \\]"},{"location":"complex_analysis/complex_numbers/#eulers-formula","title":"Euler's Formula","text":"\\[     e^{i\\theta} = cos{\\theta} + i\\sin{\\theta} \\]"},{"location":"complex_analysis/complex_numbers/#cauchy-riemann-equations","title":"Cauchy-Riemann Equations","text":"<p>For a function of a complex variable, the Cauchy-Riemann equations establish a necessary and sufficient condition for the function to be differentiable. The function \\(f(z)\\) can be split into two components, each acting on the real and imaginary parts:</p> \\[     f(z) = u(a, b) + v(a, b) \\] <p>Then the condition for differentiability is:</p> \\[     \\frac{\\partial{u}}{\\partial{a}} = \\frac{\\partial{v}}{\\partial{b}} \\quad \\quad \\frac{\\partial{u}}{\\partial{b}} = - \\frac{\\partial{v}}{\\partial{a}} \\]"},{"location":"group_theory/group_actions/","title":"Group actions","text":""},{"location":"group_theory/group_actions/#group-actions","title":"Group Actions","text":"<p>For a group \\(G\\), the group action on a set \\(X\\) is a map \\(\\phi: G \\times X \\to X\\) that takes an element \\(x \\in X\\) to a new element \\(gx \\in X\\) by the product with \\(g \\in G\\). A group action is associative: \\(g_1(g_2 x) = (g_1g_2)x\\) for \\(g_1, g_2 \\in G\\).</p> <p>As the group action maps each element of \\(X\\) to a another element of \\(X\\), i.e. taking the product of \\(g\\) with each element of \\(X\\) creates a permutation of the elements of \\(X\\), the group action can also be seen as a homomorphism between \\(G\\) and the symmetric group, \\(\\gamma: G \\to Sym(X)\\).</p>"},{"location":"group_theory/group_actions/#orbits","title":"Orbits","text":"<p>The set of elements for which a given \\(x \\in X\\) is mapped to by \\(G\\) is called the orbit of \\(x\\), denoted \\(Gx \\coloneqq \\{gx : g \\in G \\}\\).</p>"},{"location":"group_theory/group_actions/#fixed-points","title":"Fixed Points","text":"<p>The set of elements of \\(X\\) that are mapped to themselves by all \\(g \\in G\\) are called the fixed points of the group action: \\(\\{ x : gx = x \\enspace \\forall g \\in G \\}\\).</p>"},{"location":"group_theory/group_actions/#transitive-actions","title":"Transitive Actions","text":"<p>If for any \\(x, y \\in X\\) there is a \\(g \\in G\\) such that \\(gx = y\\) the group action is called transitive; since every element of \\(X\\) is mapped to every other element by some \\(g\\), there is only one orbit for a transitive group action, the entire set \\(X\\). If any \\(x \\in X\\) has the entire set \\(X\\) as its orbit then the group is transitive as this implies every element is mapped to every other element, for example:</p> \\[   g_1 x = y, \\enspace g_2 x = z \\implies g_1 g_2^{-1} z = y \\]"},{"location":"group_theory/group_actions/#faithfuleffective-actions","title":"Faithful/Effective Actions","text":"<p>An action is called faithful or effective if there are no \\(g \\in G\\) except the identity element such that \\(gx = x\\) for all \\(x \\in X\\).</p>"},{"location":"group_theory/group_actions/#free-actions","title":"Free Actions","text":"<p>TODO</p>"},{"location":"group_theory/stone_goldbart_solutions/","title":"14. Groups and Group Representations","text":""},{"location":"group_theory/stone_goldbart_solutions/#141","title":"14.1","text":"<p>Let \\(H_1\\), \\(H_2\\) be two subgroups of a group \\(G\\). Show that \\(H_1 \\cap H_2\\) is also a subgroup.</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution","title":"Solution","text":"\\[     e \\in H_1, e \\in H_2 \\implies e \\in H_1 \\cap H_2 \\quad \\text{(Identity)} \\] \\[     \\forall g \\in H_1 \\cap H_2 \\implies g \\in H_1, g \\in H_2 \\implies g^{-1} \\in H_1, g^{-1} \\in H_2 \\implies g^{-1} \\in H_1 \\cap H_2 \\quad \\text{(Inverses)} \\] \\[     \\forall g, k \\in H_1 \\cap H_2 \\implies g \\in H_1, g \\in H_2, k \\in H_1, k \\in H_2 \\implies gk \\in H_1, gk \\in H_2 \\implies gk \\in H_1 \\cap H_2 \\quad \\text{(Closure)} \\]"},{"location":"group_theory/stone_goldbart_solutions/#142-a","title":"14.2 (a)","text":"<p>Let \\(G\\) be any group.</p> <p>The subset \\(Z(G)\\) of \\(G\\) consisting of those \\(g \\in G\\) that commute with all other elements of the group is called the centre of the group. Show that \\(Z(G)\\) is a subgroup of \\(G\\).</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution_1","title":"Solution","text":"\\[     \\forall g \\in G, eg = ge \\implies e \\in Z(G) \\quad \\text{(Identity)} \\] \\[     \\exists g \\in G \\enspace | \\enspace gk = kg \\enspace \\forall k \\in G \\implies g^{-1}gkg^{-1} = g^{-1}kgg^{-1} \\iff kg^{-1} = g^{-1}k \\iff g^{-1} \\in Z(G) \\quad \\text{(Inverses)} \\] \\[     \\exists g, k \\in G \\enspace | \\enspace gc = cg, kc = ck \\enspace \\forall c \\in G \\implies gkc = gck \\iff gkc = cgk \\iff gk \\in Z(G) \\quad \\text{(Closure)} \\] <p>A similar approach shows that \\(kg \\in Z(G)\\), which is needed for closure.</p>"},{"location":"group_theory/stone_goldbart_solutions/#142-b","title":"14.2 (b)","text":"<p>If \\(g\\) is an element of \\(G\\), the set \\(C_G(g)\\) of elements of \\(G\\) that commute with \\(g\\) is called the centralizer of \\(g\\) in \\(G\\). Show that it is a subgroup of \\(G\\).</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution_2","title":"Solution","text":"\\[     \\forall g \\in G, \\enspace eg = ge \\implies e \\in C_G(g) \\quad \\text{(Identity)} \\] \\[     \\forall g \\in C_G(g), \\enspace gg^{-1} = g^{-1}g \\iff g^{-1} \\in C_G(g) \\quad \\text{(Inverses)} \\] \\[     \\exists g, k \\in G \\enspace | \\enspace gk = kg \\implies g(gk) = g(kg) \\iff g(gk) = (gk)g \\iff gk \\in C_G(g) \\quad \\text{(Closure)} \\] <p>A similar approach shows that \\(kg \\in C_G(g)\\), which is needed for closure.</p>"},{"location":"group_theory/stone_goldbart_solutions/#142-c","title":"14.2 (c)","text":"<p>If \\(H\\) is a subgroup of G, the set of elements of \\(G\\) that commute with all elements of \\(H\\) is the centralizer \\(C_G(H)\\) of \\(H\\) in \\(G\\). Show that it is a subgroup of \\(G\\).</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution_3","title":"Solution","text":"\\[     \\forall g \\in H, \\enspace eg = ge \\implies e \\in C_G(H) \\quad \\text{(Identity)} \\] \\[     \\forall g \\in H, \\enspace gg^{-1} = g^{-1}g \\iff g^{-1} \\in C_G(H), \\enspace g \\in C_G(H) \\quad \\text{(Inverses)} \\] \\[     \\exists g, k \\in G, h \\in H \\enspace | \\enspace gh = hg, \\enspace kh = hk \\implies kgh = khg \\iff (kg)h = h(kg) \\iff gk \\in C_G(H) \\quad \\text{(Closure)} \\] <p>A similar approach shows that \\(kg \\in C_G(H)\\), which is needed for closure.</p>"},{"location":"group_theory/stone_goldbart_solutions/#142-d","title":"14.2 (d)","text":"<p>If \\(H\\) is a subgroup of \\(G\\), the set \\(N_G(H) \\subset G\\) consisting of those \\(g\\) such that \\(g^{-1}Hg = H\\) is called the normalizer of \\(H\\) in \\(G\\). Show that \\(N_G(H)\\) is a subgroup of \\(G\\), and that \\(H\\) is a normal subgroup of \\(N_G(H)\\).</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution-part-1","title":"Solution (Part 1)","text":"\\[     \\forall h \\in H, \\enspace e^{-1}he \\in H \\implies e \\in N_G(H) \\quad \\text{(Identity)} \\] \\[     \\exists g \\in G \\enspace | \\enspace \\forall h \\in H, \\enspace g^{-1}hg \\in H \\implies ggg^{-1}hgg^{-1}g^{-1} = ghg^{-1} \\in H \\iff g^{-1} \\in N_G(H) \\quad \\text{(Inverses)} \\] \\[     \\exists g, k \\in G \\enspace | \\enspace \\forall h \\in H, \\enspace g^{-1}hg \\in H, \\enspace k^{-1}hk \\in H \\implies g^{-1}k^{-1}hkg \\in H \\iff (kg)^{-1}hkg \\in H \\iff kg \\in N_G(H) \\quad \\text{(Closure)} \\] <p>A similar approach shows that \\(gk \\in N_G(H)\\), which is needed for closure.</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution-part-2","title":"Solution (Part 2)","text":"<p>To show that \\(H\\) is a normal subgroup of its normalizer \\(N_G(H)\\), first show that \\(H\\) is a subset of \\(N_G(H)\\). Due to closure, taking the product of every element of the set \\(H\\) with some specific element \\(h \\in H\\) just \"reorders\" the elements in the set, but doesn't change the set itself:</p> \\[     \\forall h \\in H, \\enspace hH = Hh = H \\implies h^{-1}Hh = H \\implies H \\subset N_G(H) \\] <p>Since \\(H\\) is a subset of \\(N_G(H)\\) and is also a group then it must be a subgroup. By definition of \\(N_G(H)\\):</p> \\[     \\forall m \\in N_G(H), \\forall h \\in H, \\enspace m^{-1}hm \\in H \\implies H \\lhd N_G(H)  \\]"},{"location":"group_theory/stone_goldbart_solutions/#143","title":"14.3","text":"<p>Show that the set of powers \\(g_0^n\\) of an element \\(g_0 \\in G\\) form a subgroup. Now, let \\(p\\) be a prime number. Recall that the set \\(\\{1, 2, ..., p-1\\}\\) forms the group \\((\\mathbb{Z}_p)^{\\times}\\) under multiplication modulo \\(p\\). By appealing to Langrange's Theorem, prove Fermat's Little Theorem.</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution-part-1_1","title":"Solution (Part 1)","text":"\\[     g_0^1 = g_0 \\implies g_0^1 g_0^{-1} = g_0 g_0^{-1} \\implies g_0^0 = e \\quad \\text{(Identity)} \\] <p>By definition, the inverse of any element is also a power and works as expected:</p> \\[     g_0^n g_0^{-n} = g_0^0 = e \\quad \\text{(Inverses)} \\] <p>The product of two powers \\(n\\) and \\(k\\) is a new element with power \\(n+k\\). This property actually gives us both identity and inverses above:</p> \\[     g_0^n g_0^{k} = g_0^{n+k} \\quad \\text{(Closure)} \\]"},{"location":"group_theory/stone_goldbart_solutions/#solution-part-2_1","title":"Solution (Part 2)","text":""},{"location":"group_theory/stone_goldbart_solutions/#fermats-little-theorem","title":"Fermat's Little Theorem","text":"\\[     a^p = a \\pmod p \\quad a \\in \\mathbb{Z}, p \\in \\mathbb{P} \\] <p>Equivalently</p> \\[     a^p - a = np \\quad n \\in \\mathbb{Z} \\] <p>If \\(a\\) is coprime to \\(p\\) then</p> \\[     a^{p-1} = 1 \\pmod p \\] <p>Consider an element \\(g \\in G\\). The group \\(H = \\{g^1, g^2, ... , g^n\\}\\) must either cycle through all elements of \\(G\\) so that \\(H=G\\) if \\(g\\) is a generator, or form a subgroup \\(H \\sub G\\). If \\(g\\) is a generator then \\(g^n = e\\), that is, smaller powers of \\(g\\) cannot be the identity, otherwise higher powers can never be reached:</p> \\[     g^{n-k} = e \\implies g^{n-k}g = g \\neq g^{n - k + 1} \\] <p>Since \\(n = |H|\\) we have \\(g^{|H|} = e\\). By Lagrange's Theorem we have \\(|G| = k|H|\\) for  \\(k \\in \\mathbb{Z}\\) so therefore</p> \\[     g^{|G|} = g^{k|H|} = (g^{|H|})^k = e^k = e \\] <p>Therefore, for  \\(\\forall a \\in (\\mathbb{Z}_p)^{\\times}\\) where \\(|(\\mathbb{Z}_p)^{\\times}| = p - 1\\), and since the powers of \\(a\\) form a subgroup:</p> \\[     a^{(p-1)} = 1 \\pmod p \\]"},{"location":"group_theory/stone_goldbart_solutions/#144","title":"14.4","text":"<p>Use Fermat's Little Theorem to establish the identity underlying the algorithm for RSA public-key cryptography:</p> <p>Let \\(n = pq\\) for \\(p,q \\in \\mathbb{P}\\). Using Euclid's algorithm for the highest common factor (HCF), also known as the Greatest Common Divisor (GCD), , firstly show that if \\(\\exists k \\in \\mathbb{Z}\\) such that \\(k\\) is coprime to \\((p-1)(q-1)\\), then</p> \\[     \\exists d \\in \\mathbb{Z} \\enspace | \\enspace dk = 1 \\mod{(p-1)(q-1)} \\] <p>Then show that if </p> \\[     C = M^k \\mod{n} \\quad \\text{(Encryption)} \\] <p>then</p> \\[     M = C^d \\mod{n} \\quad \\text{(Decryption)} \\] <p>(Note: \\(e\\) is typically used to denote the encryption key, but \\(k\\) is chosen here to avoid confusion with the identity element)</p>"},{"location":"group_theory/stone_goldbart_solutions/#solution_4","title":"Solution","text":"<p>For \\(a, b \\in \\mathbb{Z^+}\\), \\(b \\lt a\\) and \\(gcd(a, b) = 1\\), that is, they are coprime, we can define the multiplicative group of integers modulo b, \\(\\mathbb{Z/nZ^{\\times}}\\). In our case, \\(gcd((p-1)(q-1), k)=1\\) so therefore we have a group where multiplication is modulo \\((p-1)(q-1)\\). Since this forms a group, \\(d = k^{-1}\\) must also be in the group such that</p> \\[     dk = 1 \\mod{(p-1)(q-1)} \\] <p>Euler's Totient Function \\(\\phi(m), m \\in \\mathbb{Z}\\) is the number of integers less that \\(m\\) that are coprime to \\(m\\), where \\(p \\in \\mathbb{P} \\iff \\phi(p) = p-1\\).</p> \\[     C^d \\mod{n} = M^{dk} \\mod n \\] \\[     dk = 1 \\mod \\phi(n) \\implies dk = u\\phi(n) + 1, u \\in \\mathbb{Z} \\] <p>The Fermat\u2013Euler Theorem for two coprime integers \\(a\\) and \\(b\\):</p> \\[     a^{\\phi(a)} = 1 \\mod{b} \\] <p>Therefore:</p> \\[     M^{dk} \\mod{n} = (M^{u\\phi(n)} \\mod{n})(M \\mod{n}) = M \\mod{n} \\]"},{"location":"linear_operators/basis_dependence/","title":"Basis dependence","text":""},{"location":"linear_operators/basis_dependence/#linear-operators","title":"Linear Operators","text":""},{"location":"linear_operators/basis_dependence/#basis-dependence","title":"Basis Dependence","text":"<p>Some operations performed on a linear operator depend on the basis chosen to represent the operator, while others do not. For a basis dependent operation we must specify in which basis we are performing the operation in order to fully describe that operation, however, for basis independent operations we do not need to specify the basis.</p>"},{"location":"linear_operators/basis_dependence/#conjugate-transpose","title":"Conjugate Transpose","text":"<p>For operators over the complex numbers, the conjugate transpose (Hermitian conjugate) is basis independent. Let \\(\\left[  A \\right] _\\alpha\\) be an operator \\(A\\) represented on the basis \\(\\alpha\\), and define a new operator \\(B\\) equal to its conjugate transpose:</p> \\[     \\left[ B\\right] _\\alpha = \\left[ A\\right] _\\alpha^{\\dagger} \\] <p>Translating the linear operator \\(A\\) to a new basis is given by a similarity transformation with a unitary operator \\(P\\):</p> \\[     \\begin{align*}         &amp; \\left[ A\\right] _\\beta = P^{-1} \\left[ A\\right] _\\alpha P \\\\         &amp; \\left[ A\\right] _\\beta^{\\dagger} = (P^{-1} \\left[ A\\right] _\\alpha P)^{\\dagger} = P^{-1} \\left[ A\\right] _\\alpha^{\\dagger} P \\\\     \\end{align*} \\] <p>The same translation can be performed on \\(B\\):</p> \\[     \\left[ B\\right] _\\beta = P^{-1} \\left[ B\\right] _\\alpha P = P^{-1} \\left[ A\\right] _\\alpha^{\\dagger} P \\] <p>We see that the relationship between \\(A\\) and \\(B\\) still holds in the new basis</p> \\[     \\left[ B\\right] _\\beta = \\left[ A\\right] _\\beta^{\\dagger} \\] <p>Having defined \\(B\\) to be the conjugate transpose of \\(A\\) in some basis, this relationship continues to hold on translating \\(A\\) and \\(B\\) to an arbitrary new basis. This is what is meant by basis independence.</p>"},{"location":"linear_operators/basis_dependence/#transpose","title":"Transpose","text":"<p>Define a linear operator \\(B\\) to be the transpose of \\(A\\)</p> \\[     \\left[ B\\right] _\\alpha = \\left[ A\\right] _\\alpha^{\\intercal} \\] <p>Translate \\(A\\) to a new basis \\(\\beta\\)</p> \\[     \\begin{align*}         &amp; \\left[ A\\right] _\\beta = P^{-1} \\left[ A\\right] _\\alpha P \\\\         &amp; \\left[ A\\right] _\\beta^{\\intercal} = (P^{-1} \\left[ A\\right] _\\alpha P)^{\\intercal} = P^{\\intercal} \\left[ A\\right] _\\alpha^{\\intercal} (P^{-1})^{\\intercal} \\\\     \\end{align*} \\] <p>Translate \\(B\\) to the same basis</p> \\[     \\left[ B\\right] _\\beta = P^{-1} \\left[ B\\right] _\\alpha P = P^{-1} \\left[ A\\right] _\\alpha^{\\intercal} P \\] <p>For the complex numbers, we that see</p> \\[     \\left[ B\\right] _\\beta \\neq \\left[ A\\right] _\\beta^{\\intercal} \\] <p>However, for the real numbers the basis translation operator \\(P\\) is orthogonal, so that</p> \\[     \\begin{align*}         &amp; \\left[ A\\right] _\\beta^{\\intercal} = P^{\\intercal} \\left[ A\\right] _\\alpha^{\\intercal} (P^{-1})^{\\intercal} = P^{-1} \\left[ A\\right] _\\alpha^{\\intercal} P \\\\         &amp; \\left[ B\\right] _\\beta = \\left[ A\\right] _\\beta^{\\intercal} \\\\     \\end{align*} \\] <p>Therefore, the transpose operation is basis dependent for the complex numbers, but basis independent for the real numbers.</p>"},{"location":"linear_operators/basis_dependence/#complex-conjugate","title":"Complex Conjugate","text":"<p>Define a linear operator \\(B\\) to be the complex conjugate of \\(A\\)</p> \\[     \\left[ B\\right] _\\alpha = \\left[ A\\right] _\\alpha^\\star \\] <p>Translate \\(A\\) to a new basis \\(\\beta\\)</p> \\[     \\begin{align*}         &amp; \\left[ A\\right] _\\beta = P^{-1} \\left[ A\\right] _\\alpha P \\\\         &amp; \\left[ A\\right] _\\beta^\\star = (P^{-1} \\left[ A\\right] _\\alpha P)^\\star = (P^{-1})^\\star \\left[ A\\right] _\\alpha^\\star P^\\star \\\\     \\end{align*} \\] <p>Translate \\(B\\) to the same basis</p> \\[     \\left[ B\\right] _\\beta = P^{-1} \\left[ B\\right] _\\alpha P = P^{-1} \\left[ A\\right] _\\alpha^\\star P \\] <p>We see that the complex conjugate is basis dependent:</p> \\[     \\left[ B\\right] _\\beta \\neq \\left[ A\\right] _\\beta^\\star \\]"},{"location":"linear_operators/representation/","title":"Representation","text":""},{"location":"linear_operators/representation/#linear-operators","title":"Linear Operators","text":""},{"location":"linear_operators/representation/#matrix-representation","title":"Matrix Representation","text":"<p>A linear operator can be represented as a matrix. Consider a linear operator \\(A: V \\rightarrow W\\) where \\(dim(V) = n\\) and \\(dim(W) = m\\). The vector spaces \\(V\\) and \\(W\\) have basis vectors \\(v_i\\) and \\(w_i\\), respectively. The following holds by linearity</p> \\[     \\begin{align*}         &amp; A(\\sum^n_{i=1} b_i v_i) = \\sum^m_{i=1} d_i w_i \\\\         &amp; \\sum^n_{i=1} b_i A v_i = \\sum^m_{i=1} d_i w_i \\\\     \\end{align*} \\] <p>Since the right-hand side is a vector in \\(W\\) and the left-hand side is a sum, this sum must be a linear combination of vectors in \\(W\\); a sum of entities which equals to a vector in some space only makes sense if it is a sum of other vectors in that same space. Therefore, we can express each element of the sum from the left-hand side as a vector in \\(W\\), where the constants \\(b_i\\) are omitted as these are the constants of the linear combination and are not part of the individual vectors.</p> \\[     \\begin{align*}         &amp; A v_i = \\sum_{k=1}^m a_{ki} w_k \\\\     \\end{align*} \\] <p>We see that \\(A\\) must be a matrix to account for all three possibilities \\(n = m\\), \\(n &lt; m\\) and \\(n &gt; m\\). For example, where \\(n = 2\\) and \\(m = 3\\):</p> \\[     \\begin{bmatrix}         a_{11} &amp; a_{12} \\\\         a_{21} &amp; a_{22} \\\\         a_{31} &amp; a_{32}     \\end{bmatrix}     \\begin{bmatrix}         v_{1} \\\\         v_{2}     \\end{bmatrix}      =     \\begin{bmatrix}         w_{1} \\\\         w_{2} \\\\         w_{3}     \\end{bmatrix} \\] <p>Finally, we see that the matrix definition of the operator \\(A\\) depends on both an input basis \\(v_i\\) and an output basis \\(w_i\\).</p>"},{"location":"machine_learning/feature_scaling/","title":"Feature scaling","text":""},{"location":"machine_learning/feature_scaling/#feature-scaling","title":"Feature Scaling","text":""},{"location":"machine_learning/feature_scaling/#motivation","title":"Motivation","text":""},{"location":"machine_learning/feature_scaling/#example-linear-regression","title":"Example: Linear Regression","text":"<p>Consider using a linear regression model for predicting the price of a house based on the number of floors and floor area in square feet. The features in the training data have ranges \\(0 \\le x_{floors} \\le 3\\) and \\(0 \\le x_{area} \\le 3500\\). Now consider what happens to the price for two houses with the same number of floors but areas 500 and 1500 \\(\\text{ft}^2\\), respectively. If \\(\\theta_{floors} \\sim \\theta_{area}\\) then the price of both houses differ by a factor of approximately 1000, the difference in area. In this model, if the first house costs $500,000 then the second would cost $500,000,000! This is clearly unrealistic. When determining the price, the feature with the larger scale has a disproportionate impact on the predicted value.</p>"},{"location":"machine_learning/feature_scaling/#example-gradient-descent","title":"Example: Gradient Descent","text":"<p>In the example above the house prices in the training data will be actual (i.e. realistic) values, and consequently we could assume that a good hypothesis function will have \\(\\theta_{floors} &gt;&gt; \\theta_{area}\\) so that the impact of \\(x_{area}\\) is reduced. However, this in turn causes problems for gradient descent. When performing gradient descent the step size \\(\\alpha\\) must be chosen small enough for \\(\\theta_i\\) with the smallest scale so as to not overshoot the minimum, however, this small \\(\\alpha\\) may dramatically slow down the convergence in the directions of \\(\\theta_i\\) with much larger scales. Adjusting all features to have similar scale can improve the efficiency of convergence.</p>"},{"location":"machine_learning/feature_scaling/#example-clustering","title":"Example: Clustering","text":"<p>Consider a model which assigns a person to a t-shirt size of either small or large. The features used to predict the assignment are mass in kilograms and height in feet. This assignment can be achieved using a clustering algorithm, where some measure is calculated for each new person and compared to the mean of this measure for the small and large samples, respectively. For example, suppose we use the Euclidean distance as measure, where \\(m\\) and \\(m_\\mu\\) are the mass and mean mass, \\(h\\) and \\(h_\\mu\\) are the height and mean height:</p> \\[     d = \\sqrt{(m - m_\\mu)^2 + (h - h_\\mu)^2} \\] <p>Let us calculate the distance for a new person whom we wish to assign a t-shirt size. The mean values from our model are as follows:</p> <ul> <li>Large: \\(m_\\mu = 80\\) , \\(h_\\mu = 6.1\\)</li> <li>Small: \\(m_\\mu = 55\\) , \\(h_\\mu = 5.2\\)</li> </ul> <p>Calculate the distance from each mean for a new person with height 6 ft and mass 67 kg:</p> <ul> <li>\\(d_{large} = 13.00\\)</li> <li>\\(d_{small} = 12.03\\)</li> </ul> <p>The person is assigned a small t-shirt size as \\(d_{small}\\) is smaller, i.e. they are closer to the mean for the small t-shirt size data. I think you would agree that a person who is 6 ft tall would be better to wear a large size! Again, we see how the feature with the larger scale is dominating the outcome.</p>"},{"location":"machine_learning/feature_scaling/#min-max-normalization","title":"Min-Max Normalization","text":"<p>Features can be scaled to the range \\([0, 1]\\) using min-max normalization:</p> \\[     x^\\prime_i = \\frac{x_i - \\min(x_i)}{\\max(x_i) - \\min(x_i)} \\] <p>Min-max normalization is sensitive to outliers; extreme values will be very close to one and cause non-extreme values to be \"squashed\" into a small interval closer to zero due to the denominator being large.</p>"},{"location":"machine_learning/feature_scaling/#mean-normalization","title":"Mean Normalization","text":"<p>Another approach to normalization subtracts the feature's mean \\(\\mu_i\\) from each value, and divides by the range:</p> \\[     x^\\prime_i = \\frac{x_i - \\mu_i}{\\max(x_i) - \\min(x_i)} \\]"},{"location":"machine_learning/feature_scaling/#z-score-normalization-standardization","title":"Z-score Normalization (Standardization)","text":"<p>Features that follow a Gaussian distribution can be scaled using standardization so that each feature \\(x_i\\) has approximately zero mean \\(\\mu_i\\) and standard deviation of 1.</p> \\[     x^\\prime_i = \\frac{x_i - \\mu_i}{\\sigma_i} \\]"},{"location":"machine_learning/feature_scaling/#choosing-a-method","title":"Choosing a Method","text":"<p>The method of rescaling to choose depends on the particular task at hand and the data. Often, multiple methods may be compared to select the most appropriate for a given situation. In certain cases care must be taken when applying rescaling, for example in linear regression rescaling must not be applied to \\(x_0 = 1\\).</p>"},{"location":"machine_learning/introduction/","title":"Introduction","text":""},{"location":"machine_learning/introduction/#what-is-machine-learning","title":"What is Machine Learning?","text":"<p>The term machine learning (ML) was coined in 1959 by Arthur Samuel, an IBM computer scientist and early pioneer in artificial intelligence. He defined machine learning as the \"field of study that gives computers the ability to learn without being explicitly programmed\".</p> <p>Computer scientist Tom Mitchell later gave a more formal definition of machine learning (1998): \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"</p> <p>For example, consider automated spam filtering of emails: * T = automated filtering of spam emails.  * E = the user manually marking an email as spam. * P = fraction of spam emails filtered automatically.</p>"},{"location":"machine_learning/introduction/#what-is-a-model","title":"What is a Model?","text":"<p>In machine learning we often speak of models. When we chose an algorithm that is suitable for the ML task at hand, we run that algorithm on a dataset and the output is our model. This process is called training the model. The dataset passed to the algorithm is called training data and is used by the algorithm to learn how to produce the desired output. The model is then used for predicting outcomes based on new input values.</p>"},{"location":"machine_learning/introduction/#machine-learning-algorithms","title":"Machine Learning Algorithms","text":"<p>Algorithms for machine learning can be broadly classified into one of a number of high-level categories.</p>"},{"location":"machine_learning/introduction/#supervised-learning","title":"Supervised Learning","text":"<p>In supervised learning the training data passed to the algorithm contains example input and output values. The algorithm learns the relationship between the input and output based on these examples. This kind of training data, which contains both the input and desired output, is called labelled data.</p>"},{"location":"machine_learning/introduction/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>In contrast to supervised learning, unsupervised learning uses training data with only input values. The algorithm discovers patterns in the data by itself without any examples of desired output. This kind of training data is called unlabelled data.</p>"},{"location":"machine_learning/introduction/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Unlike both supervised and unsupervised learning, reinforcement learning does not use either labelled or unlabelled data. An \"agent\" interacts with an environment via trial and error and is either rewarded or punished depending on the output of the model. In this way, the model is continuously trained or optimized as input data from the environment produces an output, and the model learns to produce output for which it will be rewarded.</p>"},{"location":"machine_learning/linear_regression/","title":"Linear regression","text":""},{"location":"machine_learning/linear_regression/#linear-regression-of-a-single-variable","title":"Linear Regression of a Single Variable","text":"<p>Linear regression is an example of supervised learning. In a regression problem, we aim to predict a real-valued output. By comparison, when the output is discrete-valued we use a classification algorithm. In linear regression, we establish a hypothesis function \\(h_\\theta(x)\\) which maps input \\(x\\) to output \\(y\\):</p> \\[     h_\\theta(x) = \\theta_0 + \\theta_1 x \\quad \\text{where} \\quad x, h_\\theta(x), \\theta_0, \\theta_1 \\in \\mathbb{R} \\] <p>The \\(x\\) value is called a \"feature\". This hypothesis function is the equation of a straight line:</p> <p></p>"},{"location":"machine_learning/linear_regression/#cost-function","title":"Cost Function","text":"<p>The hypothesis function \\(h(x)\\) depends on constants \\(\\theta_0\\) and \\(\\theta_1\\), but how do we choose the values for these constants? A good choice is that where the difference between \\(h_\\theta(x)\\) and the actual \\(y\\) value is minimized for all \\(n\\) training data points \\((x, y)\\). We can define a cost function which expresses this difference:</p> \\[     J(\\theta_0, \\theta_1) = \\frac{1}{n} \\sum^n_{i=1} \\left( h_\\theta(x_i) - y_i  \\right)^2 \\] <p>This cost function is the mean squared error. The square ensures only positive values for the cost. Note: some definitions include a factor of \\(1/2\\) to simplify calculations with the derivative.</p>"},{"location":"machine_learning/linear_regression/#normal-equation","title":"Normal Equation","text":"\\[     X\\theta = y \\] <p>$$ \\begin{align}        \\frac{\\partial}{\\partial \\theta} \\left( X \\theta - y  \\right)^T \\left( X \\theta - y  \\right) &amp;= 0 \\         2X^T(X \\theta - y) &amp;= 0 \\          \\theta &amp;= \\left( X^TX \\right)^{-1} X^T y \\end{align}</p> <p>$$</p>"},{"location":"machine_learning/linear_regression/#gradient-descent","title":"Gradient Descent","text":"<p>The cost function can be minimized using the gradient descent algorithm. This is also known as \"batch\" gradient descent, where all training examples are used to calculate the gradient on each iteration.</p> <ol> <li>Start with some initial \\((\\theta_0, \\theta_1)\\), for example \\((\\theta_0 = 0, \\theta_1 = 1)\\).</li> <li>Change \\((\\theta_0, \\theta_1)\\) to reduce the cost function \\(J(\\theta_0, \\theta_1)\\). By considering the cost function as a vector-valued function, this is achieved by subtracting a step in the direction of the gradient of the cost function. The gradient represents the direction of most rapid change in the function. A step size \\(\\alpha\\) must be selected.</li> </ol> \\[     \\vec{J}(\\theta_0, \\theta_1) := \\vec{J}(\\theta_0, \\theta_1) - \\alpha \\nabla \\vec{J}(\\theta_0, \\theta_1) \\quad \\text{where} \\quad \\alpha \\in \\mathbb{R}^+ \\] <ol> <li>Repeat step 2 until a minimum is reached. If \\(\\alpha\\) is too large the algorithm may overshoot the minimum and oscillate forever. Likewise, if \\(\\alpha\\) is too small the algorithm may take far too long to converge. In general, convergence to a global minimum is not guaranteed unless the cost function is convex; the definition of \\(J(\\theta_0, \\theta_1)\\) given above is convex.</li> </ol>"},{"location":"machine_learning/linear_regression/#stochastic-gradient-descent","title":"Stochastic Gradient Descent","text":"<p>A variation of the gradient descent algorithm uses a random sample of the training data to estimate the gradient. This can be useful when training on vast data sets such as with neural networks, where batch descent algorithm may perform too slowly.</p>"},{"location":"machine_learning/linear_regression/#linear-regression-of-multiple-variables","title":"Linear Regression of Multiple Variables","text":"<p>In the case where the output variable depends on multiple features, we can write the hypothesis function as follows:</p> \\[     h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n\\quad \\text{where} \\quad x_n, h_\\theta(x), \\theta_n \\in \\mathbb{R} \\] <p>Using matrix notation, we can write \\(\\theta\\) and \\(x\\) as column vectors:</p> \\[     h_\\theta(x) = \\vec{\\theta} \\cdot \\vec{x} = \\theta^Tx \\] <p>The same cost function applies in the multi-variable case, where now the input is \\(\\vec{\\theta}\\).</p>"},{"location":"machine_learning/linear_regression/#polynomial-regression","title":"Polynomial Regression","text":"\\[     h_\\theta(x) = \\sum^n_{i=0} \\theta_ix^i \\]"},{"location":"machine_learning/linear_regression/#notes","title":"Notes","text":"<ul> <li>Linear regression image taken from here under Creative Commons Licence. No changes have been made.</li> </ul>"},{"location":"machine_learning/logistic_regression/","title":"Logistic regression","text":""},{"location":"machine_learning/logistic_regression/#logistic-regression","title":"Logistic Regression","text":""},{"location":"nlp/intro/","title":"Intro","text":""},{"location":"nlp/intro/#term-frequency-inverse-document-frequency-tf-idf","title":"Term Frequency - Inverse Document Frequency (TF-IDF)","text":"<p>TF-IDF is a widely used statistical method to measure how important a term is within a document relative to a collection of documents (i.e. a corpus). How a document is defined depends on context, for example a sentence among many sentences, a page among many pages etc. \"Term\" is used as opposed to \"word\" since documents may contain words, acronyms, abbreviations etc.</p>"},{"location":"nlp/intro/#term-frequency-tf","title":"Term Frequency (TF)","text":"<p>The TF value tells us how often a term \\(t\\) appears in one specific document \\(d\\).</p> \\[ TF(t, d) = \\frac{ \\text{number of times $t$ appears in $d$} }{ \\text{total number number of terms in $d$} } \\]"},{"location":"nlp/intro/#inverse-document-frequency-idf","title":"Inverse Document Frequency (IDF)","text":"<p>The IDF value reflects what proportion of documents in the corpus contain the term. Terms that appear in only a small number of documents will have a higher value.</p> \\[ IDF(t) = \\log\\frac{ \\text{total number of documents} }{ \\text{number of documents that contain $t$} } \\] <p>The logarithm is used as when the number of words and documents increases the IDF value can explode (consider for example a web search engine using IDF in ranking search results); using the logarithm smoothes out the scale of values. No base is specified in the above equation as this can vary depending on context; base 2 and base 10 are common choices. Of course, logarithm base choices only differ by a constant factor:</p> \\[     \\log_ax = \\frac{\\log_bx}{\\log_ba} \\]"},{"location":"nlp/intro/#tf-idf","title":"TF-IDF","text":"<p>The Term Frequency - Inverse Document Frequency (TF-IDF) value is the product of TD and IDF. Terms with larger values are deemed to be more important than terms with smaller values.</p> \\[ TF\\text{-}IDF(t, d) = TF(t, d) * IDF(t) \\]"},{"location":"quantum_computation/bernstein_vazirani_algorithm/","title":"Bernstein-Vazirani Algorithm","text":""},{"location":"quantum_computation/bernstein_vazirani_algorithm/#problem-statement","title":"Problem Statement","text":"<p>Consider a function \\(f(a, x)\\) that takes two binary numbers \\(a\\) and \\(x\\) of length \\(n\\), computes their inner product and returns the value modulo 2:</p> \\[     f (a, x) = \\langle a, x \\rangle \\bmod 2 \\quad \\text{where} \\quad a, x \\in \\{0, 1\\}^n \\] <p>The function is known as an oracle as the number \\(x\\) is hidden and known only to the function, whereas we get to choose \\(a\\) and receive the output value. How can we determine \\(x\\)?</p>"},{"location":"quantum_computation/bernstein_vazirani_algorithm/#classical-solution","title":"Classical Solution","text":"<p>The value of \\(x\\) can be determined by calling \\(f\\) with \\(a\\) set to each possible permutation of the binary number with 1 in the \\(i\\)th position and zeros everywhere else, i.e. \\(\\{0_n \\dots 1, ~ 0_n \\dots 10, ~ \\dots, ~ 1_n \\dots 0\\}\\). The inner product acts as a logical AND operation for any digit pair in the two binary numbers, and by setting \\(a\\) to a number with only a single position containing a 1, if the result of \\(f\\) is 1 then it is known that \\(x\\) contains a 1 in the \\(i\\)th position. For a binary number of length \\(n\\), there are clearly \\(n\\) numbers as those just described to pass to \\(f\\), giving this classical algorithm \\(O(n)\\) time complexity to determine all positions of \\(x\\).</p>"},{"location":"quantum_computation/bernstein_vazirani_algorithm/#quantum-solution","title":"Quantum Solution","text":"<p>TODO</p> \\[     \\sum_{x \\in S^n} (-1)^{x \\cdot y} = \\begin{cases}       0 &amp; \\text{if}\\ y \\ne 0^n \\\\       2^n &amp; \\text{if}\\ y = 0^n     \\end{cases} \\]"},{"location":"quantum_computation/bernstein_vazirani_algorithm/#proof","title":"Proof","text":"<p>Case \\(y = 0^n\\):</p> \\[     \\left | S^n \\right | = 2^n \\implies \\sum_{x \\in S^n}(-1)^{x \\cdot y} = \\sum_{x \\in S^n}(-1)^{x \\cdot 0^{n}} = \\sum_{x \\in S^n}(-1)^0 = 2^n \\] <p>Case \\(y \\ne 0^n\\):</p> <p>Let \\(x = (\\ldots b_i \\ldots)^n\\) represent a string of \\(n\\) bits, where \\(b_i\\) is the bit at position \\(i\\). For each \\(x \\in S^n\\) we can define a conjugate bit string \\(\\bar{x}\\):</p> \\[     \\forall x, y \\in S^n, k \\in \\N \\ | \\ y_k = 1 \\ \\exists! \\ \\bar{x} \\in S^n \\ | \\ x \\cdot y = c \\implies \\bar{x} \\cdot y = c \\oplus 1 \\] <p>Let \\(k\\) be some number such that \\(y_k = 1\\), then by the definition of \\(x \\cdot y\\) it must be the case that</p> \\[     x = (\\ldots b_k \\ldots)^n \\implies \\bar{x} = (\\ldots b_k \\oplus 1 \\ldots)^n \\] <p>That is, by flipping only one bit \\(b_k\\) in \\(x\\), which is at the same position as \\(y_k = 1\\) in \\(y\\), we are guaranteed that \\(x \\cdot y\\) will also flip:</p> \\[     (\\ldots b_k \\ldots)^n \\cdot y = c \\implies (\\ldots b_k \\oplus 1\\ldots)^n \\cdot y = c \\oplus 1 \\] \\[     \\bar{x} \\cdot y = (x \\cdot y) \\oplus 1 \\] <p>Note that choosing a different \\(k\\) produces a different set of conjugates; the choice of \\(k\\) does not matter as long as it is fixed for all \\(x \\in S\\) and \\(y_k = 1\\). For each \\(x \\in S\\) its corresponding \\(\\bar{x}\\) is unique for the chosen \\(k\\), that is, no two bit strings have the same conjugate; suppose there is another bit string \\(a\\) such that \\(\\bar{a} = \\bar{x}\\), then</p> \\[     (\\ldots \\bar{a}_k \\ldots) = (\\ldots \\bar{x}_k \\ldots) = (\\ldots x_k \\oplus 1 \\ldots) \\implies a = x \\] <p>Now, by the definition of \\(\\bar{x}\\)</p> \\[     (-1)^{x \\cdot y} = - (-1)^{ \\bar{x} \\cdot y} \\] <p>Therefore, writing the sum to include both each \\(x_i\\) and its conjugate \\(\\bar{x}_i\\), and only summing to \\(2^n/2\\) since each expansion of the sum contains two elements, we have</p> \\[     \\sum_{x \\in S^n} (-1)^{x \\cdot y} = \\sum_{i = 1}^{2^{n-1}} (-1)^{x_i \\cdot y} + (-1)^{ \\bar{x}_i \\cdot y} = 0 \\]"},{"location":"quantum_computation/deutsch_josza_algorithm/","title":"Deutsch-Josza Algorithm","text":""},{"location":"quantum_computation/deutsch_josza_algorithm/#problem-statement","title":"Problem Statement","text":"<p>We are tasked with determining whether or not a function \\(f: \\{0, 1\\}^n  \\rightarrow \\{0, 1\\}\\) is constant or balanced with respect to its input, that is, it takes as input a binary number and returns either 0 or 1 for all possible inputs, or returns 0 for half of the input numbers and 1 for the other half, where \\(f\\) is guaranteed to be one or the other. Such a function is called a black-box or oracle, where we cannot see how it works but can only invoke it for some input and receive the corresponding output. The problem here described is known as Deutsch's Problem.</p>"},{"location":"quantum_computation/deutsch_josza_algorithm/#classical-solution","title":"Classical Solution","text":"<p>For a chosen input domain of binary numbers with maximum length \\(n\\) digits, there are \\(2^{n}\\) possible numbers. In the worst case scenario, once we have checked half of the input domain plus one we will know if the oracle is balanced or constant, that is, the oracle must be called at least \\(2^{n-1} + 1\\) times. Therefore the classical solution has running time \\(O(2^n)\\).</p>"},{"location":"quantum_computation/deutsch_josza_algorithm/#quantum-solution","title":"Quantum Solution","text":"<p>The Deutsch-Jozsa algorithm is a more general case of Deutsch's algorithm, where the input is generalized from 1 to \\(n\\) bits. We begin by preparing \\(n\\) qubits (known as the query register) in the \\(\\ket{0}\\) state and one qubit (known as the answer register) in the \\(\\ket{1}\\) state:</p> \\[     \\ket{\\Psi_0} = \\ket{0}^{\\otimes n} \\otimes \\ket{1} \\] <p>The Hadamard transform is applied to all qubits, resulting in the state</p> \\[     \\ket{\\Psi_1} = \\sum_x \\frac{ \\ket{x} }{ \\sqrt{2^n} } \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{where} \\quad x \\in \\lbrace 0, 1 \\rbrace^n \\] <p>As in Deutsch's algorithm \\(U_f\\) is defined as</p> \\[     U_f: \\ket{x,y} \\rightarrow \\ket{x, y      \\oplus f(x)} \\quad \\text{where} \\quad a \\oplus b \\coloneqq a + b \\pmod 2 \\] <p>In this case the input \\(x\\) is the query register and the input \\(y\\) is the answer register. The gate \\(U_f\\) is applied to the state \\(\\ket{\\Psi_1}\\) resulting in:</p> \\[         \\ket{\\Psi_2} = \\sum_x \\frac{ \\ket{x} }{ \\sqrt{2^{n+1}} } \\otimes \\left( \\ket{0 \\oplus f(x)} - \\ket{1 \\oplus f(x)} \\right)  \\] <p>Depending on whether \\(f(x) = 0\\) or \\(f(x) = 1\\) the sign of each \\(\\ket{x}\\) is flipped, which can be expressed as:</p> \\[         \\ket{\\Psi_2} = \\sum_x (-1)^{f(x)}\\frac{ \\ket{x} }{ \\sqrt{2^{n+1}} } \\otimes \\left( \\ket{0} - \\ket{1} \\right)  \\] <p>We see now that the results of evaluating \\(f(x)\\) on all input \\(x \\in \\{0,1\\}^n\\) are stored in the amplitudes of the superposition state of the query register. We now interfere the terms in the superposition by applying a Hadamard transform to the query register. To understand how to calculate the result of this transform, consider the familiar result of applying a Hadamard gate to the state \\(\\ket{x} =\\ket{0}\\) or \\(\\ket{x} = \\ket{1}\\). Both results can be expressed in the following equation:</p> \\[     H \\ket{x} = \\sum_k \\frac{(-1)^{xk}}{\\sqrt{2}} \\ket{k} \\quad \\text{where} \\quad k \\in \\lbrace 0, 1 \\rbrace  \\] <p>Therefore:</p> \\[    \\ket{\\Psi_3} = \\sum_x \\sum_z \\frac{ (-1)^{f(x)} (-1)^{\\vec{x} \\cdot \\vec{z}} }{2^n} \\ket{z} \\otimes \\frac{ \\left( \\ket{0} - \\ket{1} \\right) }{\\sqrt{2}}  \\quad \\text{where} \\quad \\vec{x} \\cdot \\vec{z} = \\sum_{i=1}^n x_i z_i \\quad x,z \\in \\lbrace 0, 1 \\rbrace^n \\] <p>Notice that for the state where \\(\\ket{z} = \\ket{0}^{ \\otimes n}\\), the amplitude is given by:</p> \\[     \\sum_x \\frac{ (-1)^{f(x)} }{2^n} \\] <p>If \\(f(x)\\) is constant this amplitude equals \\(+1\\) or \\(-1\\), depending on the value of \\(f(x)\\). Because of the normalization condition of a quantum state vector it follows that all other amplitudes must be zero if \\(f(x)\\) is constant. Therefore, if all qubits in the query register when measured are in the \\(\\ket{0}\\) state then \\(f(x)\\) is constant. Conversely, if \\(f(x)\\) is balanced then all the terms in the sum for the amplitude of state \\(\\ket{0}^{ \\otimes n}\\) cancel out so that this amplitude is zero; measuring the query register will result is a state where at least one qubit is \\(\\ket{1}\\).</p>"},{"location":"quantum_computation/deutschs_algorithm/","title":"Quantum Parallelism","text":""},{"location":"quantum_computation/deutschs_algorithm/#introduction","title":"Introduction","text":"<p>Consider the simple function \\(f: \\{0,1\\} \\rightarrow \\{0,1\\}\\), i.e. a one bit domain and range. The implementation of the function \\(f\\) is not important, only that we can represent it as a unitary transformation \\(U_f\\) in a quantum circuit. How can we leverage the power of quantum computation to do something with this function that a classical computer cannot do? We might start simple and consider the following circuit with a single input qubit \\(q\\) and a single output classical bit for evaluating the function:</p> <p></p> <p>If we measure the output of this circuit, however, it will behave just like a classical circuit, receiving the classical bits 0 or 1 for input qubit \\(q = \\ket{0}\\) or \\(q = \\ket{1}\\), depending on if \\(f\\) is constant or balanced. There is nothing extraordinary about this circuit. What about leveraging superposition by first applying a Hadamard gate?</p> <p></p> <p>Until it is measured, the output state this time is a superposition, however, if \\(f\\) is balanced then the output is indistinguishable from the output of the Hadamard gate; we cannot tell for which input \\(x\\) we have measured \\(f(x)\\)</p> \\[     \\frac{\\ket{f(0)} + \\ket{f(1)}}{\\sqrt{2}} = \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\] <p>If \\(f\\) is constant we will receive always 0 or always 1, but again, there is nothing that really sets this circuit apart from the previous circuit; it is no more interesting that a classical circuit. Instead, consider the following circuit with two input qubits and two output classical bits, where the input qubits are both in the ground state:</p> \\[     q_0 = \\ket{0} \\quad q_1 = \\ket{0} \\] <p></p> <p>Whatever the implementation of \\(f\\), we can implement the gate \\(U_f\\) so that </p> \\[     U_f: \\ket{x,y} \\rightarrow \\ket{x, y \\oplus f(x)} \\quad \\text{where} \\quad a \\oplus b \\coloneqq a + b \\pmod 2 \\] <p>where \\(x\\) is the first input of the gate (\\(q_0\\)), and \\(y\\) the second input (\\(q_1\\)). In the circuit, both input qubits are prepared in the state \\(\\ket{0}\\) and then a Hadamard gate is applied to \\(q_0\\) leaving the two states:</p> \\[     q_0 = \\frac{ \\ket{0} + \\ket{1} }{\\sqrt{2}} \\quad q_1 = \\ket{0} \\] <p>Since \\(q_1\\) is prepared in the state \\(\\ket{0}\\), addition modulo 2 with this qubit is equivalent to evaluating the function on the gate's input \\(x\\):</p> \\[     0 \\oplus f(x) = f(x) \\] <p>The gate \\(U_f\\) therefore results in the output state</p> \\[     \\frac{ \\ket{0, f(0)} + \\ket{1, f(1)} }{\\sqrt{2}} \\] <p>This is a remarkable state! In a single application of the gate \\(U_f\\) the output state contains both values \\(f(0)\\) and \\(f(1)\\), and unlike before, we know for which input we have received \\(f(x)\\) due to the value of the first qubit. Of course, if we measure the output state we will get information on only one of the values of \\(f(x)\\) and not both, since the superposition will collapse.</p>"},{"location":"quantum_computation/deutschs_algorithm/#generalizing-to-n-qubits","title":"Generalizing to N Qubits","text":"<p>Applying a Hadamard gate to \\(n\\) qubits in parallel, an operation known as the Hadamard transform, with each in the initial state \\(\\ket{0}\\), results in the state:</p> \\[     \\frac{1}{\\sqrt{2^n}} \\sum_x \\ket{x} \\] <p>where the sum is over all possible values of \\(x\\). Thus, parallel evaluation of a function with n-bit input \\(x\\) and 1-bit output, \\(f(x)\\), can be achieved in the following way:</p> <ol> <li>Prepare the initial \\(n+1\\) qubit state \\(\\ket{0}^{\\otimes n}\\ket{0}\\).</li> <li>Apply a Hadamard gate to the first \\(n\\) qubits.</li> <li>Apply the quantum circuit \\(U_f\\) implementing the function \\(f\\).</li> </ol> <p>The outcome of the steps above is the state</p> \\[     \\frac{1}{\\sqrt{2^n}} \\sum_x \\ket{x} \\ket{f(x)} \\] <p>Although the resulting state is a superposition of all possible outcomes of \\(f\\), we can only measure one value. Quantum computation requires something more than just quantum parallelism in order to extract information about more than one value of \\(f\\). Deutsch's algorithm demonstrates one example.</p>"},{"location":"quantum_computation/deutschs_algorithm/#deutschs-algorithm","title":"Deutsch's Algorithm","text":"<p>Suppose we do not know if the function \\(f\\) is constant or balanced, that is, is it the case that \\(f(0) = f(1)\\) or \\(f(0) \\ne f(1)\\)? Let us start with the states</p> \\[     q_0 = \\ket{0} \\quad q_1 = \\ket{1} \\] <p>Consider the circuit shown below where a Hadamard gate is applied to both input qubits:</p> <p></p> <p>The Hadamard gates produce the following total state:</p> \\[     \\begin{align*}         \\ket{\\Psi_1} &amp;= \\left( \\frac{ \\ket{0} + \\ket{1} }{ \\sqrt{2} } \\right) \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\\\         &amp;= \\frac{ \\ket{00} - \\ket{01} + \\ket{10} - \\ket{11} }{2} \\\\     \\end{align*} \\] <p>Depending on the value of \\(f(x)\\) for the qubit \\(q_0\\), after applying the gate \\(U_f\\) there are four possible output states which can be  written concisely as:</p> \\[     \\sum_x (-1)^{f(x)} \\ket{x} \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{where} \\quad x \\in \\{0, 1\\}  \\] <p>Writing out the four states for clarity:</p> \\[     \\begin{align*}         &amp; f(0) = 0, f(1) = 1 \\\\         &amp; \\ket{\\Psi_2} = \\frac{ \\ket{00} - \\ket{01} + \\ket{11} - \\ket{10} }{2} \\\\     \\end{align*} \\] \\[     \\begin{align*}         &amp; f(0) = 1, f(1) = 0 \\\\         &amp; \\ket{\\Psi_2} = \\frac{ \\ket{01} - \\ket{00} + \\ket{10} - \\ket{11} }{2} \\\\     \\end{align*} \\] \\[     \\begin{align*}         &amp; f(0) = 0, f(1) = 0 \\\\         &amp; \\ket{\\Psi_2} = \\frac{ \\ket{00} - \\ket{01} + \\ket{10} - \\ket{11} }{2} \\\\     \\end{align*} \\] \\[     \\begin{align*}         &amp; f(0) = 1, f(1) = 1 \\\\         &amp; \\ket{\\Psi_2} = \\frac{ \\ket{01} - \\ket{00} + \\ket{11} - \\ket{10} }{2} \\\\     \\end{align*} \\] <p>The only difference between these output states is that the sign is flipped for each ket. We can group the output states by whether or not \\(f\\) is balanced or constant:</p> \\[     \\begin{align*}         \\pm \\left( \\frac{ \\ket{0} + \\ket{1} }{ \\sqrt{2} } \\right) \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{(constant)} \\\\         \\pm \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{(balanced)} \\\\     \\end{align*} \\] <p>Applying the final Hadamard gate to \\(q_0\\) we have the possible states</p> \\[     \\begin{align*}         \\pm \\ket{0} \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{(constant)} \\\\         \\pm \\ket{1} \\otimes \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\quad \\text{(balanced)} \\\\     \\end{align*} \\] <p>Since \\(f(0) \\oplus f(1) = 0\\) if \\(f\\) is constant and 1 if \\(f\\) is balanced, the state can be written concisely as</p> \\[     \\pm \\ket{f(0) \\oplus f(1)} \\left( \\frac{ \\ket{0} - \\ket{1} }{ \\sqrt{2} } \\right) \\] <p>Therefore, by measuring the qubit \\(q_0\\) we can determine if the function is balanced or constant, having applied the gate \\(U_f\\) only once, i.e. having evaluated \\(f\\) only once. Any classical solution must evaluate the function \\(f\\) at least two times, thus showing how a quantum algorithm can outperform any possible classical algorithm for this problem. The essence of many quantum algorithms is a that clever choice of \\(U_f\\) and applying something like the Hadamard gate allows different values of the function to interfere with one another, allowing us to deduce some global property of the function.</p>"},{"location":"quantum_computation/teleportation/","title":"Quantum Teleportation","text":"<p>Consider a superposition qubit state that Alice wishes to send to Bob:</p> \\[     \\ket{\\Psi_A} = \\alpha \\ket{0}  + \\beta \\ket{1} \\] <p>Due to the No-Cloning Theorem this state cannot be copied, however, using quantum teleporation this state can be transferred to Bob. In what follows, the linear algebra calculations are written out explicitly to demonstrate the full procedure.</p> <p>Alice and Bob share an entangled pair given by</p> \\[     \\ket{\\Psi_{AB}} = \\frac{1}{\\sqrt{2}} (\\ket{00} + \\ket{11}) \\] <p>The total state of the three-qubit system is given by the following, where by convention the first two qubits in the 3-qubit basis states are Alice's and the third is Bob's:</p> \\[     \\begin{align*}         \\ket{\\Psi_{total}} &amp;= \\ket{\\Psi_A} \\otimes \\ket{\\Psi_{AB}} \\\\         &amp;= (\\alpha \\ket{0}  + \\beta \\ket{1}) \\otimes \\frac{1}{\\sqrt{2}} (\\ket{00} + \\ket{11}) \\\\         &amp;= \\frac{1}{\\sqrt{2}} \\left( \\alpha \\ket{000} + \\alpha \\ket{011} + \\beta \\ket{100} + \\beta \\ket{111} \\right)     \\end{align*} \\] <p>Using this convention saves us from using awkward notation such as \\(\\ket{0_{Alice} 0_{Alice} 0_{Bob}}\\). Going forward, the tensor product symbol may be dropped for brevity. The state vector \\(\\ket{\\Psi_{total}}\\) is 8-dimensional as there are  3 qubits giving \\(2^3\\) possible combinations for basis states:</p> \\[     \\ket{000}, \\ket{001}, \\ket{010}, \\ket{011}, \\ket{100}, \\ket{101}, \\ket{110}, \\ket{111} \\] <p>Writing the vector in matrix notation, where the order matches the basis states' order above:</p> \\[     \\Psi_{total}^\\intercal = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} &amp; \\alpha &amp; 0 &amp; 0 &amp; \\alpha &amp; \\beta &amp; 0 &amp; 0 &amp; \\beta &amp; \\end{bmatrix} \\] <p>Alice now applies a CNOT gate to her two qubits. As the CNOT gate operates on two qubits, i.e. the basis states \\(\\ket{00}, \\ket{01}, \\ket{10}, \\ket{11}\\), it is typically presented as a \\(4 \\times 4\\) matrix:</p> \\[     CNOT_4 = \\begin{bmatrix}         &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\\\         &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp;     \\end{bmatrix} \\] <p>As the state \\(\\Psi_{total}\\) is 8-dimensional, we need to express the CNOT operator in 8 dimensions also:</p> \\[     CNOT_8 \\Psi_{total} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}         &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\\\         &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\\\     \\end{bmatrix}  \\begin{bmatrix} \\alpha \\\\\\ 0 \\\\\\ 0 \\\\\\ \\alpha \\\\\\ \\beta \\\\\\ 0 \\\\\\ 0 \\\\\\ \\beta \\end{bmatrix} = \\begin{bmatrix} \\alpha \\\\\\ 0 \\\\\\ 0 \\\\\\ \\alpha \\\\\\ 0 \\\\\\ \\beta \\\\\\ \\beta \\\\\\ 0 \\end{bmatrix}  \\] <p>Now, the total state is given by</p> \\[     \\ket{\\Psi_{total}} = \\frac{1}{\\sqrt{2}} \\left( \\alpha \\ket{000} + \\alpha \\ket{011} + \\beta \\ket{110} + \\beta \\ket{101} \\right) \\] <p>Next, a Hadamard gate is applied to Alice's first qubit. The total state can be refactored, noting that \\(\\ket{0} \\otimes \\ket{01} = \\ket{001}\\) etc.:</p> \\[     H = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}         &amp; 1 &amp; 1 &amp; \\\\         &amp; 1 &amp; -1 &amp; \\\\     \\end{bmatrix} \\] \\[     \\ket{\\Psi_{total}} = \\frac{1}{\\sqrt{2}} \\left[ \\alpha \\ket{0} \\left( \\ket{00} + \\ket{11} \\right) + \\beta \\ket{1} \\left( \\ket{10} + \\ket{01} \\right) \\right] \\] \\[     \\begin{align*}         H \\ket{\\Psi_{total}} &amp;= \\frac{1}{2} \\left[ \\alpha H \\ket{0} \\left( \\ket{00} + \\ket{11} \\right) + \\beta H \\ket{1} \\left( \\ket{10} + \\ket{01} \\right) \\right] \\\\         &amp;= \\frac{1}{2} \\left[ \\alpha \\left( \\ket{0} + \\ket{1} \\right) \\left( \\ket{00} + \\ket{11} \\right) + \\beta \\left(\\ket{0} - \\ket{1} \\right) \\left( \\ket{10} + \\ket{01} \\right) \\right] \\\\         &amp;= \\frac{1}{2} \\left[ \\alpha \\ket{00} \\left( \\ket{0} + \\ket{1} \\right) + \\alpha \\ket{11} \\left( \\ket{0} + \\ket{1} \\right) + \\beta \\ket{10} \\left(\\ket{0} - \\ket{1} \\right) + \\beta \\ket{01} \\left(\\ket{0} - \\ket{1} \\right) \\right] \\\\     \\end{align*} \\] <p>The above can be refactored using the associativity of the tensor product:</p> \\[     \\ket{a} \\otimes \\ket{b} \\otimes \\ket{c} = \\ket{a} \\otimes \\ket{bc} = \\ket{ab} \\otimes \\ket{c} = \\ket{abc} \\] <p>This associativity property allows us to group Alice's qubits into two-qubit basis states and isolate Bob's qubits into one-qubit basis states:</p> \\[     \\begin{align*}         \\ket{\\Psi_{total}} &amp;= \\frac{1}{2} \\left[ \\alpha \\ket{00} \\left( \\ket{0} + \\ket{1} \\right) + \\alpha \\ket{11} \\left( \\ket{0} + \\ket{1} \\right) + \\beta \\ket{10} \\left(\\ket{0} - \\ket{1} \\right) + \\beta \\ket{01} \\left(\\ket{0} - \\ket{1} \\right) \\right] \\\\         &amp;= \\frac{1}{2} \\left[ \\alpha\\ket{0}\\ket{00} + \\alpha\\ket{0}\\ket{11} + \\alpha\\ket{1}\\ket{00} + \\alpha\\ket{1}\\ket{11} + \\beta\\ket{0}\\ket{10} + \\beta\\ket{0}\\ket{01} - \\beta\\ket{1}\\ket{10} - \\beta\\ket{1}\\ket{01} \\right] \\\\         &amp;= \\frac{1}{2} \\left[ \\alpha\\ket{00}\\ket{0} + \\alpha\\ket{01}\\ket{1} + \\alpha\\ket{10}\\ket{0} + \\alpha\\ket{11}\\ket{1} + \\beta\\ket{01}\\ket{0} + \\beta\\ket{00}\\ket{1} - \\beta\\ket{11}\\ket{0} - \\beta\\ket{10}\\ket{1} \\right] \\\\         &amp;= \\frac{1}{2} \\left[ \\ket{00}(\\alpha\\ket{0} + \\beta\\ket{1}) + \\ket{01}(\\alpha\\ket{1} + \\beta\\ket{0}) + \\ket{10}(\\alpha\\ket{0} - \\beta\\ket{1}) + \\ket{11}(\\alpha\\ket{1} - \\beta\\ket{0}) \\right]     \\end{align*} \\] <p>The total state is now naturally separated into four terms. If Alice performs a measurement and receives the state \\(\\ket{00}\\), for example, then Bob's qubit will be in the state \\(\\alpha\\ket{0} + \\beta\\ket{1}\\), which is the original state we wished to transmit! Of course, to know which state his qubit is in, Alice must send her measurement outcome to Bob, i.e. in order for the quantum state to be teleported Alice must send two classical bits to Bob. Bob can recover the original state by performing the following operations on his state, once he knows Alice's measurement outcome:</p> \\[     \\begin{align*}         &amp; \\ket{00} \\rightarrow I \\quad \\text{(identity)} \\\\         &amp; \\ket{01} \\rightarrow X \\quad \\text{(Pauli X-gate)} \\\\         &amp; \\ket{10} \\rightarrow Z \\quad \\text{(Pauli Z-gate)} \\\\         &amp; \\ket{11} \\rightarrow ZX \\quad \\text{(Pauli Z and X-gate)} \\\\     \\end{align*} \\] <p>TODO - differentiate each state symbol after gate is applied.</p>"},{"location":"quantum_mechanics/introduction/","title":"Introduction","text":""},{"location":"quantum_mechanics/introduction/#what-is-quantum-mechanics","title":"What is Quantum Mechanics?","text":"<p>Quantum mechanics is the study of the fundamental working of Nature on the smallest scales, that of atoms, molecules, particles and below.</p>"},{"location":"quantum_mechanics/introduction/#history","title":"History","text":""},{"location":"quantum_mechanics/introduction/#19th-century-physics","title":"19th Century Physics","text":"<p>To begin to understand quantum mechanics it is instructive to understand the history of how the theory came about. By the end of the 19th century, all of physics was ultimately described by two foundational theories, Newtonian Mechanics and Electromagnetism. Newtonian mechanics, based on the foundations of Isaac Newton and others in the 17th century, described matter and its motion, summarized by Newton's famous equation:</p> \\[   \\vec{F} = m \\frac{ \\mathrm{d} \\vec{p} }{\\mathrm{dt}} = m \\vec{a} \\] <p>The theory of Electromagnetism, expressed by the equations of James Clerk Maxwell earlier in the 19th century, described electromagnetic radiation. The two theories were bridged by the Lorentz Force Law, which described how matter and electromagnetic waves interacted.</p> \\[   \\vec{F} = q \\left( \\vec{E} + \\vec{v} \\times \\vec{B} \\right) \\] <p>Crucially, particle and wave properties were mutually exclusive: matter never behaved like a wave, electromagnetic radiation never behaved like a particle. However, there were a few unsolved problems ...</p>"},{"location":"quantum_mechanics/introduction/#unsolved-problems","title":"Unsolved Problems","text":""},{"location":"quantum_mechanics/introduction/#blackbody-radiation","title":"Blackbody Radiation","text":"<p>The graph below shows a plot of the measured intensity (arbitrary units) of an electromagnetic wave against its wavelength. It had been observed experimentally that the energy intensity</p> <p></p>"},{"location":"quantum_mechanics/schrodinger_equation/","title":"Schrodinger equation","text":""},{"location":"quantum_mechanics/schrodinger_equation/#schrodinger-equation","title":"Schr\u00f6dinger Equation","text":"\\[     i \\hbar \\frac {\\partial{\\Psi(x,t)}}{\\partial{t}} = \\hat{H} \\Psi(x,t) \\] <p>For a single, non-relativistic particle, the Hamiltonian operator \\(\\hat{H}\\) is given by the sum of the kinetic and potential energies:</p> \\[     \\hat{H} = -\\frac{\\hbar^2}{2m} \\nabla^2  + V(x,t) \\]"},{"location":"quantum_mechanics/schrodinger_equation/#time-independent-form","title":"Time-Independent Form","text":"<p>Consider a potential that only depends on position, \\(V(x)\\). Perform separation of variables on the Schr\u00f6dinger equation to write the wave function as follows:</p> \\[     \\Psi(x,t) = \\phi(x)\\omega(t) \\] <p>This is not always possible for an arbitrary function, as can be seen with the following counter example where the exponential cannot be split into a product of two other functions \\(g\\) and \\(h\\):</p> \\[     f(x,t) = e^{xt} \\ne g(x) h(t) \\tag{1} \\] <p>Let us make an assumption that the wavefunction can be split as above, and see what happens. </p> \\[     \\begin{align*}         &amp; i \\hbar \\phi(x) \\frac {\\partial{\\omega(t)}}{\\partial{t}} = \\left[ -\\frac{\\hbar^2}{2m} \\nabla^2  + V(x) \\right]\\phi(x)\\omega(t) \\\\         &amp; \\frac{i \\hbar}{\\omega(t)} \\frac {\\partial{\\omega(t)}}{\\partial{t}} = \\frac{1}{\\phi(x)} \\left[ -\\frac{\\hbar^2}{2m} \\nabla^2 \\phi(x) + V(x) \\phi(x) \\right] \\\\     \\end{align*} \\] <p>The LHS depends only on time and the RHS depends only on position. For both sides to be equal they must equal a constant. Let us call this constant \\(E\\):</p> \\[     \\frac{1}{\\phi(x)} \\left[ -\\frac{\\hbar^2}{2m} \\nabla^2 \\phi(x) + V(x) \\phi(x) \\right] = E \\] <p>We can now write the following time-independent form, which we can see is an eigenvalue equation for the Hamiltonian:</p> \\[     \\hat{H} \\phi(x) = E \\phi(x) \\] <p>In what kind of physical situation is this relevant? The electrostatic field felt by an electron can be modeled by \\(V(x)\\), with contributions from the electrostatic field of the atomic nucleus and other electrons. If we hypothesise that the electron's wave function takes the form of a stationary wave then we can indeed perform a separation of variables as above.</p>"},{"location":"real_analysis/power_series/","title":"Power series","text":""},{"location":"real_analysis/power_series/#power-series","title":"Power Series","text":""},{"location":"real_analysis/power_series/#cosx","title":"cos(x)","text":"\\[     \\cos(x) = \\sum_{n=0}^{\\infty} \\frac{(-1)^{n} x^{2n}}{2n!} = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\ldots \\]"},{"location":"real_analysis/power_series/#sinx","title":"sin(x)","text":"\\[     \\sin(x) = \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!} = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\ldots \\]"},{"location":"set_theory/results/","title":"Results","text":""},{"location":"set_theory/results/#power-set","title":"Power Set","text":"<p>The power set \\(\\mathcal{P}\\) of a set \\(S\\) is the set of all subsets. The notation \\(2^{S}\\) is sometimes used because \\(|\\mathcal{P}| = 2^{|S|}\\).</p>"},{"location":"set_theory/results/#proof","title":"Proof","text":"<p>Let \\(|S| = n\\)</p> \\[     \\begin{align*}         {n \\choose 0} + {n \\choose 1} + {n \\choose 2} + \\dots + {n \\choose n} \\\\         \\sum_{k=0}^{n} \\frac{n!}{k!(n-k)!} \\\\     \\end{align*} \\]"},{"location":"special_relativity/galilean_relativity/","title":"Special Relativity","text":""},{"location":"special_relativity/galilean_relativity/#galilean-relativity","title":"Galilean Relativity","text":"<p>In classical mechanics, we can translate the position or velocity between two different inertial frames of reference, \\(S\\) and \\(S'\\), using what we call the Galilean transformations. Assuming that we start our clock when the the origins of the two frames coincide, that is the time \\(t_0=0\\), and that the frames are moving relative to each other at a speed \\(v\\) in the y-direction, then at a later time \\(t_1\\) the frames are separated by a distance \\(vt_1\\) in the y-direction.</p> <p>TODO - diagram</p> \\[     \\begin{align*}         &amp; y' = y - vt \\\\         &amp; x' = x \\\\         &amp; z' = z \\\\         &amp; t' = t \\\\     \\end{align*} \\]"},{"location":"special_relativity/galilean_relativity/#michelson-morley-experiment","title":"Michelson-Morley Experiment","text":"<p>James Clerk Maxwell's theory of electromagnetism, published in 1861, described light as a wave and predicted the speed of light \\(c\\) in a vacuum as</p> \\[     c = \\frac{1}{\\sqrt{\\epsilon_0 \\mu_0}} \\approx 3 \\times 10^{8} ms^{-1} \\] <p>where \\(\\epsilon_0\\) and \\(\\mu_0\\) are the electric permittivity and magnetic permeability of the vacuum, respectively. But if light is a wave, in what medium does it travel through the vacuum? Mechanical waves that we are familiar with, such as a wave moving through water or sound through air, travel though a medium, so it was postulated that light travels through the \"luminiferous aether\", a substance that permeated all of space.</p> <p>The Michelson-Morley experiment (1887) attempted to measure the motion of the Earth relative to this aether by interferring two beams of light, one which travelled parallel to the Earth's motion around the Sun (\\(B_1\\)) and one which travelled perpendicular (\\(B_2\\)). An interference pattern was expected due to the relative motion of the Earth and \\(B_1\\) in the same direction changing the speed that \\(B_1\\) travelled.</p> <p>No interference pattern was observed, which cast doubt on the existence of the aether. If light travels in a medium, how can its speed be constant when measured in reference frames with different velocities relative to this medium?</p>"},{"location":"special_relativity/galilean_relativity/#einsteins-postulates","title":"Einstein's Postulates","text":"<p>In 1905 Albert Einstein postulated the following:</p> <ol> <li>The laws of physics are the same in all inertial reference frames.</li> <li>The speed of light is the same in all inertial reference frames.</li> </ol> <p>The implications of these two postulates are profound.</p>"},{"location":"special_relativity/galilean_relativity/#lorentz-contraction","title":"Lorentz Contraction","text":"<p>To rescue the idea of the aether, Hendrik Lorentz (1891) and George Francis Fitzgerald (1889) postulated length contraction.</p>"},{"location":"special_relativity/spacetime/","title":"Special Relativity","text":""},{"location":"special_relativity/spacetime/#the-spacetime-interval","title":"The Spacetime Interval","text":"<p>When we speak of an event we speak of something that occurs at a point in space and at a particular moment in time. Now consider a signal propagating at the speed of light \\(c\\). The signal begins at time \\(t_1\\) at coordinates \\((x_1,y_1,z_1)\\) in the reference frame \\(K\\), and eventually reaches a point \\((x_2,y_2,z_2)\\) at time \\(t_2\\). The distance travelled between the two events is \\(c \\Delta t\\) but by the Pythagorean theorem the following must be true:</p> \\[     (\\Delta x)^2 + (\\Delta y)^2 + (\\Delta z)^2 - c^2(\\Delta t)^2 = 0 \\] <p>We can also measure these events in another reference frame \\(K'\\) where the signal begins at time \\(t'_1\\) at coordinates \\((x'_1,y'_1,z'_1)\\) and arrives at the point \\((x'_2,y'_2,z'_2)\\) at time \\(t'_2\\). By the same reasoning above we have:</p> \\[     (\\Delta x')^2 + (\\Delta y')^2 + (\\Delta z')^2 - c^2(\\Delta t')^2 = 0 \\] <p>We see that this interval, for two events in the propagation of a signal travelling at the speed of light, is always zero in any reference frame. Now consider two arbitrary events separated in space and time. We define the spacetime interval for these events as the difference between the separation of the events in space and the distance light would travel in the time between the events:</p> \\[     (\\Delta s)^2 = (\\Delta x)^2 + (\\Delta y)^2 + (\\Delta z)^2 - c^2(\\Delta t)^2  \\] <p>For events that are infinitessimally close in space and time we can define:</p> \\[     (ds)^2 = (dx)^2 + (dy)^2 + (dz)^2 - c^2(dt)^2  \\]"},{"location":"statistics/chi_squared_test/","title":"Chi squared test","text":""},{"location":"statistics/chi_squared_test/#pearsons-chi-squared-test","title":"Pearson's Chi-Squared Test","text":"<p>Pearson's chi-squared test, also written \\(\\chi^2\\), is one of a number of statistical tests that use the \\(\\chi^2\\) distribution. This test is applied to sets of categorical data, i.e. variables which can take only a limited and fixed number of values. The test evaluates how likely it is that any observed difference between the sets of data arose due to chance.</p> <p>The \\(\\chi^2\\) statistic is defined as follows, where \\(O_i\\) and \\(E_i\\) are the \\(i\\)-th observed and expected values of the categorical variable, respectively:</p> \\[     \\chi^2 = \\sum^n_{i=1} \\frac{(O_i - E_i)^2}{E_i} \\] <p>There are three kinds of comparison in Pearson's \\(\\chi^2\\) test, each of which is explained below.</p>"},{"location":"statistics/chi_squared_test/#size-requirement","title":"Size Requirement","text":"<p>The expected frequency of each value of the categorical variable must be \\(\\ge 5\\). While not exact, this is a rule of thumb to help ensure the distribution of the test statistic adequately matches a \\(\\chi^2\\) distribution.</p>"},{"location":"statistics/chi_squared_test/#type-1-goodness-of-fit","title":"Type 1 - Goodness of Fit","text":"<p>In this test the aim is to determine if the observed frequency of the  values of the categorical variable differ from the expected frequency in a statistically significant manner, or if the difference is down to chance. </p> <p>The number of degrees of freedom is given below, where \\(k\\) is the number of categories of the random variable:</p> \\[     df = k - 1 \\]"},{"location":"statistics/chi_squared_test/#example","title":"Example","text":"<p>Suppose that the national average percentages of commuters that use each mode of transport to commute was collected by a census and is known. We want to determine if a particular city follows this national average. We perform a random sample of commuters in the city with sample size \\(n=1000.\\) The data are shown in the table below.</p> Category Observed % Expected % Observed Count Expected Count Car 0.75 0.76 750 760 Motorcycle 0.11 0.10 110 100 Bicycle 0.03 0.05 30 50 Walking 0.03 0.03 30 30 Bus 0.06 0.02 60 20 Tram 0.02 0.04 20 40 <p>The hypotheses for our test are as follows:</p> <ul> <li>\\(H_0\\) - the city follows the national average, i.e. the values in the \"expected\" column.</li> <li>\\(H_A\\) - the city does not follow the national average.</li> </ul> <p>Compute the test statistic:</p> \\[     \\chi^2 = 0.13 + 1 + 8 + 0 + 80 + 10 = 99.13 \\] <p>Using a standard table we finding the critical value by looking up the row that corresponds to the degrees of freedom \\(df = 5\\) and the column for our chosen significance level \\(\\alpha = 5\\)%. The critical value is 11.07. We reject \\(H_0\\) because \\(99.13 &gt; 11.07\\). In other words, it is statistically unlikely that we would measure the observed values that we did and that the population, i.e. the commuters of the city, would use modes of transport that follow the national average. We conclude that the city's commuters do not follow the national average.</p>"},{"location":"statistics/chi_squared_test/#type-2-independence","title":"Type 2 - Independence","text":"<p>In this test the aim is to determine if two categorical variables are related, that is, if the value of either one of the variables depends on the value of the other.</p>"},{"location":"statistics/chi_squared_test/#example_1","title":"Example","text":""},{"location":"statistics/chi_squared_test/#type-3-homogeneity","title":"Type 3 - Homogeneity","text":"<p>TODO</p>"},{"location":"statistics/continuous_probability_distributions/","title":"Continuous probability distributions","text":""},{"location":"statistics/continuous_probability_distributions/#statistics-of-continuous-probability-distributions","title":"Statistics of Continuous Probability Distributions","text":"<p>The theory of statistics of discrete probability distributions can be readily extended to that of continuous probability distributions. Probabilities are now provided using a probability density function \\(f(x)\\). The normalization condition is expressed as: $$ \\int\\limits_{-\\infty}^\\infty f(x) dx = 1 $$</p>"},{"location":"statistics/continuous_probability_distributions/#probability-density","title":"Probability Density","text":"<p>The probability of any single value of \\(X\\) is zero. This may seem counter-intuitive, however, consider that since the random variable is continuous then there are an infinite number of possible values it can take. Since the total probability is spread out over an infinite number of values, each value must have an infinitely small probability.</p> <p>For continuous random variables, we do not ask what is the probability of one specific value \\(x\\) occurring, but rather what is the probability of \\(x\\) occuring in some interval:</p> \\[ P(\\alpha \\le X \\le \\beta) = \\int\\limits_\\alpha^\\beta f(x) dx \\] <p>Since the probability of any specific value occurring is zero, the following are equivalent:</p> \\[ P(\\alpha \\le X \\le \\beta) = P(\\alpha \\lt X \\lt \\beta) = P(\\alpha \\le X \\lt \\beta) = P(\\alpha \\lt X \\le \\beta)  \\]"},{"location":"statistics/continuous_probability_distributions/#proof","title":"Proof","text":"\\[ \\begin{align} P(X \\le c) &amp;= P((X \\lt c) \\cup P(X = c)) \\\\            &amp;= P(X \\lt c) + P(X = c) - P((X \\lt c) \\cap P(X = c)) \\\\            &amp;= P(X \\lt c) + 0 - 0 \\\\            &amp;= P(X \\lt c) \\\\ \\end{align} \\]"},{"location":"statistics/continuous_probability_distributions/#expected-value","title":"Expected Value","text":"\\[     E[X] = \\int\\limits_{-\\infty}^\\infty x f(x)dx \\]"},{"location":"statistics/continuous_probability_distributions/#variance","title":"Variance","text":"\\[     Var[X] = \\int\\limits_{-\\infty}^\\infty (x-E[X])^2 f(x)dx \\]"},{"location":"statistics/continuous_probability_distributions/#sample-mean-variance","title":"Sample Mean &amp; Variance","text":"<p>Since a sample from any population contains a finite number of values, the equations for sample mean and variance for a discrete random variable also apply in the continuous case.</p>"},{"location":"statistics/continuous_probability_distributions/#cumulative-distribution-function","title":"Cumulative Distribution Function","text":"<p>The CDF is given by:</p> \\[     CDF(\\alpha) = P(X \\le \\alpha )  \\int\\limits_{-\\infty}^\\alpha x f(x)dx \\]"},{"location":"statistics/continuous_probability_distributions/#normal-distribution","title":"Normal Distribution","text":"<p>The most important probability distribution is the normal distribution, also known as a Gaussian distribution or bell curve due to its shape. The center is given by the mean \\(\\mu\\), and the standard deviation \\(\\sigma\\) determines how \"spread out\" the graph is. It is defined as follows:</p> \\[ f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}{(\\frac{x-\\mu}{\\sigma})^2}} \\] <p>Many phenomena in nature can be approximated quite well by a normal distribution, for example, people's heights, the size of snowflakes, and IQ scores.</p>"},{"location":"statistics/continuous_probability_distributions/#central-limit-theorem","title":"Central Limit Theorem","text":"<p>In its basic form, the Central Limit Theorem states that for a sample of size \\(n\\) with sample mean \\(\\overline{x}\\) and sample standard deviation \\(s\\), where all observations are i.i.d, then the following limit approaches a normal distribution:</p> \\[     \\lim_{n\\to\\infty} \\frac{ \\overline{x} - \\mu } { s } \\] <p>where the sample standard deviation is given by:</p> \\[     s = \\frac{ \\sigma } { \\sqrt{n} } \\] <p>In other words, the Central Limit Theorem tells us that given many separate samples from a population, each with many observations, the sample means will tend towards a normal distribution, provided that the sample sizes were large enough. For example, imagine sampling the height's of thousands of adults in many countries around the world. The sample means of the heights for each country would be approximately normally distributed.</p>"},{"location":"statistics/continuous_probability_distributions/#68-95-997-rule","title":"68-95-99.7 Rule","text":"<p>68%, 95%, and 99.7% of the values lie within one, two, and three standard deviations of the mean, respectively.</p>"},{"location":"statistics/discrete_probability_distributions/","title":"Discrete probability distributions","text":""},{"location":"statistics/discrete_probability_distributions/#discrete-probability-distributions","title":"Discrete Probability Distributions","text":"<p>We begin our study of statistics with the theory of discrete random variables. We denote the set of all possible values that the random variable can take as \\(X\\). Specific values of the random variable are denoted in lower case \\(x\\). A random variable obeys some probability distribution \\(P(X): \\mathbb{R} \\mapsto \\mathbb{R}\\) such that we can obtain the probability of a specific value of \\(X\\) occurring. The probability distribution obeys the normalization condition:</p> \\[ \\sum_{i=1}^{n} P(x_i) = 1 \\]"},{"location":"statistics/discrete_probability_distributions/#expected-value","title":"Expected Value","text":"<p>For a discrete probability distribution \\(X\\) with \\(n\\) possible values, where \\(x_i\\) is the i-th possible value and \\(p_i\\) is the probability of that value, the expected value (or expectation) is given by</p> \\[ \\mu_X = E[X] = \\sum_{i=1}^{n} x_i P(x_i) \\] <p>Where the distribution X is clear the symbol \\(\\mu\\) may also be used. The expectated value is a weighted average. Note the usage of square brackets here to denote that this is a functional, i.e. a function of other functions (probability distributions); this notation is not consistent. The notation \\(\\overline{X}\\) is also used, and \\(\\braket{X}\\) is common in physics.</p>"},{"location":"statistics/discrete_probability_distributions/#linearity","title":"Linearity","text":"<p>The expected value is linear, no matter if the distributions are dependent or independent:</p> \\[ E[X + Y] = E[X] + E[Y] \\]"},{"location":"statistics/discrete_probability_distributions/#law-of-large-numbers","title":"Law of Large Numbers","text":"<p>When \\(n\\) samples are taken from a probability distribution \\(X\\) their average value approaches the expected value as the number of samples increases. This is an intuitive result.</p> \\[ \\lim_{n \\to \\infty } \\sum_{i=1}^{n} \\frac{X_i}{n} = E[X] \\]"},{"location":"statistics/discrete_probability_distributions/#variance","title":"Variance","text":"<p>The variance of a discrete random variable, written \\(Var[X]\\) or often simply \\(\\sigma^2\\), is the expected value of the square of the difference between the variable and its expected value:</p> \\[ \\sigma^2 = Var[X] = E[(X - E[X])^2] \\] <p>The variance quantifies the dispersion of samples from a probability distribution, that is, the weighted average (squared) spread of samples from the expected value. It can also be expressed as </p> \\[ Var[X] = E[X^2] - E[X]^2 \\]"},{"location":"statistics/discrete_probability_distributions/#derivation","title":"Derivation","text":"\\[  \\begin{align*} E[(X - E[X])^2] &amp;= \\sum_{i=1}^{n} (x_i - \\sum_{k=1}^{n} x_k p_k )^2 p_i \\\\                 &amp;= \\sum_{i=1}^{n} (x_i^2 - 2 x_i \\sum_{k=1}^{n} x_k p_k + (\\sum_{k=1}^{n} x_k p_k)^2) p_i \\\\                 &amp;= \\sum_{i=1}^{n} x_i^2 p_i- 2 \\sum_{i=1}^{n} x_i p_i \\sum_{k=1}^{n} x_k p_k + \\sum_{i=1}^{n} p_i(\\sum_{k=1}^{n} x_k p_k)^2 \\\\                 &amp;= E[X^2]- 2 E[X]^2 + (1)E[X^2] \\\\                 &amp;= E[X^2]- E[X]^2 \\\\ \\end{align*} \\]"},{"location":"statistics/discrete_probability_distributions/#_1","title":"Discrete probability distributions","text":""},{"location":"statistics/discrete_probability_distributions/#why-the-squared-difference","title":"Why the Squared Difference?","text":"<p>The squared difference ensures that the value for all samples is always positive or zero, but the absolute value $ |X - E[X]| $ could also provide this property. There are a number of reasons why the squared difference is used:</p> <ul> <li>The squared difference is continuously differentiable (it exists and is itself continuous), whereas the absolute value's derivate is not continuous, it is undefined at $ x = 0 $ . This is useful when trying to optimize the variance.</li> <li>If $ X_n $ are independent discrete random variables then the following is true for the squared difference, unlike the absolute value:</li> </ul> \\[ Var[X_1 + ... + X_n] = Var[X_1] + ... + Var[X_n] \\]"},{"location":"statistics/discrete_probability_distributions/#standard-deviation","title":"Standard Deviation","text":"<p>The square root of the variance is called the standard deviation:</p> \\[  \\sigma = SD[X] = \\sqrt{Var[X]} \\] <p>The standard deviation is expressed in the same units as the underlying variable, whereas the variance is expressed in squared units. Which is used depends on the context, however, sometimes one is mathematically more useful. For example, the expression above for \\(Var[X_1 + ... + X_n]\\) does not apply to the standard deviation:</p> \\[  SD[X_1 + ... X_n] \\neq SD[X_1] + ... + SD[X_n] \\]"},{"location":"statistics/discrete_probability_distributions/#population-vs-sample-values","title":"Population vs. Sample Values","text":"<p>Care must be taken when referring to statistics about an entire population (often unknown) versus samples taken from that population. More correctly, the values that refer to the entire population are  parameters of the distribution. We can estimate the values of population parameters using sampling. A sample statistic is unbiased if the expectation value equals the population parameter, otherwise it is known as a biased statistic.</p>"},{"location":"statistics/discrete_probability_distributions/#sample-mean","title":"Sample Mean","text":"<p>The sample mean provides an estimate of the population mean, and is an arithmetic average over the sample values:</p> \\[ \\overline{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i \\] <p>The expected value of the sample mean is the population mean:</p> \\[ E[\\overline{x}] = \\mu  \\] <p>The variance of the sample mean approaches zero as the sample sizes increases, since the sample mean itself approaches the population mean:</p> \\[ Var[\\overline{x}] = \\frac{\\sigma^2}{n} \\]"},{"location":"statistics/discrete_probability_distributions/#proof","title":"Proof","text":"\\[ \\begin{align*} Var[\\overline{x}] &amp;= Var \\left[ \\frac{1}{n} \\sum_{i=1}^{n} x_i \\right] \\text{xc} \\\\                   &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} Var[x_i]   \\\\ \\end{align*} \\] <p>TODO - complete</p>"},{"location":"statistics/discrete_probability_distributions/#sample-variance","title":"Sample Variance","text":"\\[ s^2 =  \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\] <p>The expected value of the sample variance is the population variance:</p> \\[ E[s^2] = \\sigma^2  \\]"},{"location":"statistics/discrete_probability_distributions/#bessels-correction","title":"Bessel's Correction","text":"<p>The factor of \\(\\frac{1}{n-1}\\) in the sample variance is known as Bessel's Correction. Intuitively it may appear that an arithmetic average over the values should be taken, similar to the sample mean, however, this produces an underestimation, i.e. a biased statistic. </p>"},{"location":"statistics/discrete_probability_distributions/#proof_1","title":"Proof","text":"<p>First, let us show that the following produces a biased statistic:</p> \\[ s_{b}^2 =  \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\] <p>Manipulate the expected value:</p> \\[ \\begin{align*}     E[s_{b}^2] &amp;= E \\left[ \\frac{1}{n}\\sum_{i=1}^{n} (x_i^2 - 2x_i\\overline{x} + \\overline{x}^2) \\right] \\\\             &amp;= E \\left[ \\frac{1}{n}\\sum_{i=1}^{n} x_i^2 - 2\\overline{x} \\frac{1}{n}\\sum_{i=1}^{n} x_i + \\frac{1}{n}\\sum_{i=1}^{n}\\overline{x}^2 \\right] \\\\             &amp;= E \\left[ \\frac{1}{n}\\sum_{i=1}^{n} x_i^2 - 2\\overline{x}^2 + \\overline{x}^2 \\right] \\\\             &amp;= E \\left[ \\frac{1}{n}\\sum_{i=1}^{n} x_i^2 \\right] - E[\\overline{x}^2] \\\\             &amp;= \\frac{1}{n}\\sum_{i=1}^{n} E[x_i^2] - E[\\overline{x}^2] \\\\             &amp;= \\frac{1}{n} (n E[x_i^2] ) - E[\\overline{x}^2] \\\\             &amp;= E[x_i^2] - E[\\overline{x}^2] \\\\ \\end{align*} \\] <p>The second last line holds since \\(x_i\\) represents an observation, and all observations (it is assumed) are i.i.d. Therefore the expected value of any obversation is the same, i.e. \\(E[x_i] = \\mu\\).</p> <p>From the definition of variance:</p> \\[ \\begin{align*}     E[x_i^2] &amp;= Var[x_i] + E[x_i]^2 \\\\             &amp;= \\sigma^2 + \\mu^2 \\end{align*} \\] <p>We also know that \\(Var[\\overline{x}] = \\frac{\\sigma^2}{n}\\), therefore:</p> \\[ \\begin{align*}     E[\\overline{x}^2] &amp;= Var[\\overline{x}] + E[\\overline{x}]^2 \\\\                       &amp;= \\frac{\\sigma^2}{n} + \\mu^2 \\end{align*} \\] <p>Bringing the above together:</p> \\[ \\begin{align*}     E[s_{b}^2] &amp;= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 \\\\                 &amp;= \\left( 1 - \\frac{1}{n} \\right) \\sigma^2 \\end{align*} \\] <p>The expected value of the sample variance \\(s_b^2\\) is biased, that is, it is not equal to the population variance and must be corrected by the inverse factor on the right-hand side to obtain a non-biased result:</p> \\[ \\begin{align*}     \\sigma^2 &amp;= \\frac{n}{n-1}E[s_{b}^2]\\\\              &amp;= \\left( \\frac{n}{n-1} \\right) \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\\\              &amp;= \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\overline{x})^2 \\end{align*} \\]"},{"location":"statistics/discrete_probability_distributions/#cumulative-distribution-function","title":"Cumulative Distribution Function","text":"<p>It is useful to define the cumulative distribution function, written \\(CDF\\), which represents the probability of a random variable being less than or equal to some value:</p> \\[     CDF(x) = P(X \\le x) = \\sum_{X \\le x} P(x)  \\]"},{"location":"statistics/discrete_probability_distributions/#binomial-distribution","title":"Binomial Distribution","text":"<p>TODO - add diagram</p>"},{"location":"statistics/discrete_probability_distributions/#definition","title":"Definition","text":"<p>Consider a random experiment where each outcome can have one of two possible values: success with probability \\(p\\) or failure with probability \\(1-p\\). These events or trials are known as Bernoulli Trials. Each trial is independent of the others as the probability remains the same. An example of a Bernoulli Trial is tossing a coin to check for heads vs. tails.</p> <p>The discrete probability distribution of obtaining exactly \\(k\\) successes from \\(n\\) Bernoulli Trials is given by the binomial distribution:</p> \\[ P(k, n, p) = {n \\choose k} p^k (1-p)^{n-k} \\] <p>where the binomial coefficient (often read as \"\\(n\\) choose \\(k\\)\") is</p> \\[ {n \\choose k} = \\frac{n!}{k!(n-k)!} \\] <p>The binomial distribution is a probability mass function as it gives the probability that a discrete random variable is exactly equal to some value.</p> <p>For \\(n\\) trials each with probability \\(p\\) the mean is clearly given by</p> \\[\\mu = np\\]"},{"location":"statistics/hypothesis_testing/","title":"Hypothesis testing","text":""},{"location":"statistics/hypothesis_testing/#hypothesis-testing","title":"Hypothesis Testing","text":"<p>Suppose we have a hypothesis about a population and we wish to determine if it is true or false using statistics. The scenario where it false is called the null hypothesis \\(H_0\\), and where it is true is called the alternative hypothesis \\(H_A\\). Using a hypothesis test we determine if we should accept \\(H_0\\) or reject it, thereby accepting \\(H_A\\). Hypothesis testing is also known as significance testing.</p>"},{"location":"statistics/hypothesis_testing/#critical-value-vs-p-value","title":"Critical Value vs. P-Value","text":"<p>There are two equivalent approaches to performing a hypothesis test. In both cases, we essentially ask the same thing: \"assuming \\(H_0\\) is true, is the probability that I would observe my measured value less than or equal to \\(\\alpha\\)?\", where \\(\\alpha\\) is some chosen probability called the significance level such as 1%, 5% etc. If the answer from the test is yes, then we reject \\(H_0\\) as it is unlikely (under the chosen significance level) to obtain the measured value if \\(H_0\\) is true.</p>"},{"location":"statistics/hypothesis_testing/#critical-value-approach","title":"Critical Value Approach","text":"<p>With the critical value approach it is determined whether or not the observed test statistic is more extreme than a defined critical value. We reject \\(H_0\\) if the test statistic is more extreme than the critical value, otherwise we accept it. The critical value is selected based on two factors: * A chosen probability \\(\\alpha\\) called the significance level, such as 1%, 5% etc. * The probability distribution of the test statistic.</p> <p>The critical value divides the area under the probability distribution curve into rejection region(s) and a non-rejection region.</p>"},{"location":"statistics/hypothesis_testing/#left-tailed-test","title":"Left-Tailed Test","text":"<p>Let \\(\\phi(z)\\) be a probability density function, \\(c\\) the critical value and \\(\\alpha\\) the significance level:</p> \\[     \\alpha = \\int^{c}_{-\\infty} \\phi(z)dz \\] <p>For a test statistic \\(m\\), when \\(m \\le c\\) we accept \\(H_A\\) . In other words, with a left-tailed or left-sided test \\(H_0\\) is rejected if the test statistic falls within the left rejection region:</p> <p></p>"},{"location":"statistics/hypothesis_testing/#right-tailed-test","title":"Right-Tailed Test","text":"\\[     \\alpha = \\int^{\\infty}_{c} \\phi(z)dz \\] <p>For a test statistic \\(m\\), when \\(m \\ge c\\) we accept \\(H_A\\) . In other words, with a right-tailed or right-sided test \\(H_0\\) is rejected if the test statistic falls within the right rejection region:</p> <p></p>"},{"location":"statistics/hypothesis_testing/#two-tailed-test","title":"Two-Tailed Test","text":"<p>In a two-tailed test, the total significance level is divided between two regions, i.e. the probability that the test statistic is less than or equal to a critical value \\(c_1\\) or that it's greater than or equal to a critical value \\(c_2\\)</p> \\[     \\alpha = \\int^{c_1}_{-\\infty} \\phi(z)dz \\ + \\ \\int^{\\infty}_{c_2} \\phi(z)dz \\] <p>For a test statistic \\(m\\), when \\(m \\le c_1\\) or \\(m \\ge c_2\\) we accept \\(H_A\\) . When the probability density function is symmetric then \\(c_1 = - c_2\\), but some distributions used in hypothesis testing are asymmetric, for example the chi-squared distribution. In other words, with a two-tailed or two-sided test \\(H_0\\) is rejected if the test statistic falls within either of the two rejection regions, illustrated below for a symmetric distribution:</p> <p></p>"},{"location":"statistics/hypothesis_testing/#p-value-approach","title":"P-Value Approach","text":"<p>In the p-value approach we evaluate the probability of observing a value at least as extreme as the test statistic, assuming \\(H_0\\) is true. In contrast to the critical value approach where we know the probability \\(\\alpha\\) but wish to determine the critical value in the integral limit, this time around we know the critical value and wish to determine the probability \\(p(z)\\). The p-value is then compared against the significance level \\(\\alpha\\). For a test statistic \\(z\\) we have:</p> \\[ p(z) \\le \\alpha = \\begin{cases} \\text{true} \\implies \\text{reject $H_0$} \\\\     \\text{false} \\implies \\text{accept $H_0$} \\end{cases} \\] <p>The smaller the p-value, the stronger the evidence against \\(H_0\\). The p-value can be used to show the exact level of evidence for or against \\(H_0\\) without reference to a signficance level, unlike the critical value method.</p>"},{"location":"statistics/hypothesis_testing/#calculating-critical-values-p-values","title":"Calculating Critical Values &amp; P-Values","text":"<p>In practice, critical values and p-values are obtained using statistical software or standard tables. Calculating values under a distribution such as the normal distribution is difficult and typically solved using numerical methods.</p>"},{"location":"statistics/hypothesis_testing/#notes","title":"Notes","text":"<p>Images taken from here under Creative Commons Licence. No changes have been made.</p>"},{"location":"statistics/introduction/","title":"Introduction","text":""},{"location":"statistics/introduction/#introduction","title":"Introduction","text":""},{"location":"statistics/introduction/#what-is-statistics","title":"What is Statistics?","text":"<p>The German word Statistik, itself derived from Latin, had a now obsolete meaning \"description of a state\". In statistics, we are concerned with populations, and we wish to make summary statements about the state of these populations by sampling when it is simply impractical, or perhaps impossible, to learn about all members of a population. In this sense, we wish to determine the value of some state of the population. For example, it is at least impractical to determine the average height of every adult human on Earth by measuring billions of people, but by taking well-chosen samples we can determine a good approximation.</p>"},{"location":"statistics/introduction/#descriptive-vs-inferential-statistics","title":"Descriptive vs. Inferential Statistics","text":"<p>Statistical techniques fall into two broad categories. Descriptive statistics describe or summarize data, for example mean or standard deviation. With descriptive statistics there is no uncertainty as the reported statistics simply describe the data as measured. Descriptive statistics are used for creating graphs and charts such as histograms and pie charts. With inferential statistics the goal is to infer or estimate properties of a population based on sampling. Inferential techniques include hypothesis testing.</p>"},{"location":"statistics/maximum_likelihood_estimation/","title":"Maximum likelihood estimation","text":""},{"location":"statistics/maximum_likelihood_estimation/#maximum-likelihood-estimation","title":"Maximum Likelihood Estimation","text":"<p>Suppose there is a random sample \\(X_1, ... , X_n\\) whose probability distribution depends on some unknown parameter \\(\\theta\\). The method of Maximum Likelihood enables us to find a point estimator for the parameter. A point estimator is so-called because it estimates the value of the parameter by selecting a specific value out of the parameter space \\(\\Theta\\), that is, the space of all possible values for that parameter. As an example, if a random sample was taken from a distribution assumed to be normal then the goal would be to find a point estimator for the mean \\(\\mu\\). </p> <p>It seems reasonable that a good estimate of the parameter \\(\\theta\\) would be that value which maximizes the probability of observing those values which were observed. For a random sample, where the probability mass or density function is \\(f(x ; \\theta)\\), the joint probability is given by</p> \\[     L(\\theta) = P(X_1 = x_1, ... , X_n = x_n) = \\prod_{i=1}^{n} f(x_i ; \\theta) \\] <p>The point estimate for \\(\\theta\\) from the set \\(\\Theta\\) of possible values is given by</p> \\[     \\hat{\\theta} = \\underset{\\theta \\in \\Theta}{\\mathrm{argmax}}\\ L(\\theta) \\] <p>The point estimate can be found by differentiating the likelihood function \\(L(\\theta)\\) to find a maximum:</p> \\[     \\frac{\\partial L(\\theta)}{\\partial \\theta} = 0 \\quad \\quad \\frac{\\partial^2 L(\\theta)}{\\partial \\theta^2} &lt; 0 \\]"},{"location":"statistics/power_transforms/","title":"Power transforms","text":""},{"location":"statistics/power_transforms/#power-transforms","title":"Power Transforms","text":"<p>Many statistical methods assume that the data on which they operate is normally distributed. Data that is non-normal, for example highly skewed data, may be difficult to analyse, and applying many standard methods will fail. By applying a transform to the data, the statistical methods that assume normality can now be used.</p>"},{"location":"statistics/power_transforms/#box-cox-transform","title":"Box-Cox Transform","text":"<p>By defining the variable \\(w = (y^{\\lambda} - 1)/\\lambda\\) we obtain a useful transform of the variable \\(y\\). When \\(\\lambda = 1\\) the transform is a simple linear transformation, meaning our data is already normally distributed. Other values of \\(\\lambda\\) can be chosen, depending on the distribution of the data. When \\(\\lambda = 0\\) the transform as defined above is indetermine, however we can find the transform for this case using L'H\u00f4pital's Rule, taking the derivative with respect to \\(\\lambda\\):</p> \\[     \\lim_{\\lambda \\to 0} w(\\lambda) = \\frac{ \\lim_{\\lambda \\to 0} (y^{\\lambda} - 1) }{ \\lim_{\\lambda \\to 0} \\lambda } = \\frac{ \\lim_{\\lambda \\to 0} (y^{\\lambda} - 1)^\\prime }{ \\lim_{\\lambda \\to 0} \\lambda^\\prime } = \\frac{ \\lim_{\\lambda \\to 0} y^\\lambda \\ln(y) }{ \\lim_{\\lambda \\to 0} 1 } = \\ln(y) \\] <p>The general formulation for the Box-Cox transform is therefore given by:</p> \\[     w(\\lambda) = \\begin{cases} \\ln(y) \\quad \\text{if} \\quad \\lambda = 0 \\\\     (y^{\\lambda} - 1)/\\lambda \\quad if \\quad \\lambda \\ne 0 \\end{cases} \\] <p>The parameter \\(\\lambda\\) is chosen so as to provide the best fit to a normal distribution. Typically, many values of \\(\\lambda\\) may be tested until the one that results in a best-fit to a normal distribution is found. Lambda is chosen using variety of methods including:</p> <ul> <li>Maximum Likehood</li> <li>Goodness of Fit tests</li> </ul>"},{"location":"statistics/power_transforms/#yeo-johnson-transform","title":"Yeo-Johnson Transform","text":"<p>TODO</p>"},{"location":"statistics/t_test/","title":"T test","text":""},{"location":"statistics/t_test/#students-t-test","title":"Student's T-Test","text":""},{"location":"statistics/t_test/#one-sample-test","title":"One-Sample Test","text":"<p>When performing a z-test the population standard deviation must be known. The point of a z-test is to test if the population's hypothesized mean is correct. It is unlikely that one would know the population standard deviation \\(\\sigma\\) but not know the population mean. To solve this problem we can use a t-test, where we instead use the sample standard deviation \\(s\\) as an estimate of \\(\\sigma\\):</p> \\[    t = \\frac {\\overline{x} - \\mu_0} { s / \\sqrt n  } \\] <p>The t-test is in a sense the \"best we can do\" without knowing the population standard deviation.</p>"},{"location":"statistics/t_test/#degrees-of-freedom","title":"Degrees of Freedom","text":"<p>Consider choosing three numbers such that their mean is 9. If you choose 3 and 3, then the third number must also be 3. Similarly, if you choose 1 and 6 then the third number must be 2. We see that for \\(n\\) numbers we can only freely choose \\(n-1\\); once these are chosen the final number is fixed. The number of freely varying parameters is called the degrees of freedom.</p>"},{"location":"statistics/t_test/#t-distribution","title":"T-Distribution","text":"<p>The t-statistic follows the t-distribution whose probability density function is given by the following, where \\(\\Gamma\\) is the gamma function:</p> \\[    f(t|\\nu) = \\frac{ \\Gamma( \\frac{\\nu + 1}{2}) }{ \\sqrt{\\nu \\pi} \\Gamma( \\frac{\\nu}{2} ) } \\left(1 + \\frac{t^2}{\\nu} \\right)^{-( \\frac{ \\nu + 1}{2} ) } \\] <p>The probability density function converges to the standard normal distribution as the degrees of freedom \\(\\nu\\) increases:</p> <p></p>"},{"location":"statistics/time_series_forecasting/","title":"Time series forecasting","text":""},{"location":"statistics/time_series_forecasting/#time-series-forecasting","title":"Time-Series Forecasting","text":""},{"location":"statistics/time_series_forecasting/#random-noise","title":"Random Noise","text":"<p>TODO autocorrelation mean and var of models</p>"},{"location":"statistics/time_series_forecasting/#autoregressive-model-ar","title":"Autoregressive Model (AR)","text":"<p>If we model a value \\(y_t\\), that is, the value \\(y\\) of a time series at some time \\(t\\), as a linear combination of values at previous times, we have the autoregressive model. The name refers to the fact that \\(y_t\\) is a regression on previous values of the series, i.e. on previous values of itself. We use the notation \\(y_t\\) as this represents the value at a specific time \\(t\\), whereas \\(y(t)\\) refers to a function that represents the entire series. The AR model of order \\(n\\) is given by:</p> \\[     AR(n): \\quad y_t = c + \\epsilon_t + \\sum^n_{i=1} \\phi_i y_{t-i} \\] <p>where \\(c\\) is a constant, \\(\\epsilon_t\\) is the random noise present at time \\(t\\), and \\(\\phi_i\\) are the model parameters, i.e. how much each previous value \\(y_{t-i}\\) contributes to \\(y_t\\). The values \\(y_{t-i}\\) are known as lags.</p>"},{"location":"statistics/time_series_forecasting/#moving-average-model-ma","title":"Moving Average Model (MA)","text":"\\[     MA(n): \\quad y_t = \\mu + \\epsilon_t + \\sum^n_{i=1} \\theta_i \\epsilon_{t-i} \\]"},{"location":"statistics/time_series_forecasting/#arma-model","title":"ARMA Model","text":"<p>TODO - where did the constant and mean go?</p> \\[     ARMA(p,q): \\quad y_t = \\epsilon_t + \\sum^p_{i=1} \\phi_i y_{t-i} + \\sum^q_{i=1} \\theta_i \\epsilon_{t-i} \\]"},{"location":"statistics/z_test/","title":"Z test","text":""},{"location":"statistics/z_test/#z-score","title":"Z-Score","text":"<p>The z-score or standard score tells by how many standard deviations a value differs from the mean. This is useful when comparing values from different populations, each having their own parameters \\(\\mu\\) and \\(\\sigma\\), allowing the values to be compared in standard units.</p> \\[     z = \\frac {{x} - \\mu} {\\sigma} \\] <p>Clearly, the standard score follows the same distribution as the measured values \\(x\\) as it is simply rescaled via subtraction and division.</p>"},{"location":"statistics/z_test/#z-test","title":"Z-Test","text":"<p>When a hypothesis is about the mean of a distribution we can use a z-test. The z-statistic is defined as follows, where \\(\\mu_0\\) is the population mean under the null hypothesis and \\(\\sigma\\) is the known (i.e. actual, real) population variance:</p> \\[     z = \\frac {\\overline{x} - \\mu_0} { \\sigma / \\sqrt n } \\] <p>Fron the Central Limit Theorem we know that the sample mean \\(\\overline{x}\\) is approximately normally distributed, so the same distribution applies to the z-statistic. Note that the z-statistic in this case is essentially the same as above for the z-score; the difference between the measured value and the population mean is divided by the population standard deviation. For samples of size \\(n\\), the standard deviation of the distribution of \\(\\overline{x}\\) is \\(\\sigma / \\sqrt{n}\\).</p> <p>It should be recognised that the z-test has limited practical use as it is unrealistic to think that we'd find ourselves in the situation of knowing the population variance, but not the population mean. However, it serves as a useful introduction to hypothesis testing and more powerful methods.</p>"},{"location":"statistics/z_test/#z-table","title":"Z-Table","text":"<p>A standard table for the z-statistic can be used for determining both critical values and p-values. Of course, software is used frequently instead of standard tables.  Cells within the table represent the area under the standard normal curve to the left of the z-score. A standard table shows values for the standard normal cumulative distribution function:</p> \\[     \\Phi(c) = p(z \\le c) = \\frac{1}{\\sqrt{2\\pi}}  \\int\\limits_{-\\infty}^c  e^{-\\frac{1}{2}z^2} dz \\] <p>We can find the probability for a value greater than the critical value using: $$     p(z \\ge c) = 1 - \\Phi(z) $$</p> <p>Since the standard normal distribution is symmetric about \\(z = 0\\) this implies that</p> \\[ p(z \\ge c) = p(-z \\le -c) \\]"},{"location":"statistics/z_test/#how-to-read-a-z-table","title":"How to Read a Z-Table","text":"<p>The key to using a z-table is the following: * Row headings define the z-score to the tenth decimal place. * Column headings add the hundredth decimal place.</p> <p>For example, to find the critical value for a z-value of 1.27, find the row in the left-most column for 1.2 and then the column on that row for 0.07; the resulting critical value is 0.8980. A sample is show at the end of this page. To use the table, we first determine the</p>"},{"location":"statistics/z_test/#test-criteria","title":"Test Criteria","text":"<p>The criteria for performing a test, for both the critical value and p-value approaches, are shown below, where \\(c_\\alpha\\) is the critical value for a significance level \\(\\alpha\\).</p>"},{"location":"statistics/z_test/#left-tailed-test","title":"Left-Tailed Test","text":"\\[     z \\le c_\\alpha \\quad \\text{where} \\quad z, c_\\alpha \\lt 0 \\tag{critical value approach} \\] \\[     p(z) \\le \\alpha \\tag{p-value approach} \\]"},{"location":"statistics/z_test/#right-tailed-test","title":"Right-Tailed Test","text":"\\[     z \\ge c_\\alpha \\quad \\text{where} \\quad z, c_\\alpha \\gt 0 \\tag{critical value approach} \\] \\[     p(z) \\le \\alpha \\tag{p-value approach} \\]"},{"location":"statistics/z_test/#two-tailed-test","title":"Two-Tailed Test","text":"<p>For a two-tailed test the criteria depend on whether our z-value is positive or negative: $$     z \\ge c_\\alpha \\quad \\text{where} \\quad z, c_\\alpha \\gt 0 \\tag{critical value approach} $$</p> \\[     p(z) \\le \\frac{\\alpha}{2}  \\tag{p-value approach} \\] <p>Or:</p> \\[     z \\le c_\\alpha \\quad \\text{where} \\quad z, c_\\alpha \\lt 0 \\tag{critical value approach} \\] \\[     p(z) \\le \\frac{\\alpha}{2}  \\tag{p-value approach} \\]"},{"location":"statistics/z_test/#example","title":"Example","text":"<p>It is claimed that the mean grade for students in a university is 75. We ask, is this claim true? A random sample of grades of size 100 gives a sample mean of 73. It is known that the population standard deviation is 15.</p> <ul> <li>\\(H_0\\) - the mean grade is 75.</li> <li>\\(H_A\\) - the mean grade is not 75.</li> </ul> <p>Calculate the z-statistic:</p> \\[ z = \\frac{73 - 75}{\\frac{15}{\\sqrt{100}}} = -1.33 \\] <p>For our test we choose a significance level of 5%. Using the critical value approach, we will look up the value using a standard z-table (of course, you could use software). Since \\(H_A\\) is about \\(\\mu_A \\ne \\mu_0\\) being different, which includes both \\(\\mu_A \\lt \\mu_0\\) and \\(\\mu_A \\gt \\mu_0\\), we have a two-tailed test. </p> <p>What is the critical value for a significance level of 0.05? Since we have a two-sided test the probability (significance level) is split into 0.025 for each tail of the distribution. Find the cell in the table for the probability 0.975 (i.e. \\(1 - 0.025\\)); this is row 1.9 and column 0.06. Therefore the critical value for \\(\\alpha = 0.05\\) in a two-sided test is \\(\\pm1.96\\). We perform the following check:</p> \\[ -1.33 \\le -1.96 \\implies \\text{false} \\] <p>Therefore we reject \\(H_A\\) and accept \\(H_0\\).</p> <p>We can repeat the same test but this time use the p-value approach. Looking up the p-value from the z-table: \\(p(z \\le 1.33) =0.9082\\). Therefore \\(p(z \\ge 1.33) = 1 - p(z \\le 1.33) = 1 - 0.9082 = 0.092\\). Since the standard normal distribution is symmetric about \\(z = 0\\) we know that \\(p(z \\ge 1.33) = p(-z \\le -1.33)\\). Therefore, as $ 0.092 \\gt 0.05$ we reject \\(H_A\\) and accept \\(H_0\\).</p>"},{"location":"statistics/z_test/#appendix","title":"Appendix","text":""},{"location":"statistics/z_test/#z-table-sample","title":"Z-Table Sample","text":"z + 0.00 + 0.01 + 0.02 + 0.03 + 0.04 + 0.05 + 0.06 + 0.07 + 0.08 + 0.09  0.0  0.50000 0.50399 0.50798 0.51197 0.51595 0.51994 0.52392 0.52790 0.53188 0.53586  0.1  0.53983 0.54380 0.54776 0.55172 0.55567 0.55962 0.56360 0.56749 0.57142 0.57535  0.2  0.57926 0.58317 0.58706 0.59095 0.59483 0.59871 0.60257 0.60642 0.61026 0.61409  0.3  0.61791 0.62172 0.62552 0.62930 0.63307 0.63683 0.64058 0.64431 0.64803 0.65173  0.4  0.65542 0.65910 0.66276 0.66640 0.67003 0.67364 0.67724 0.68082 0.68439 0.68793  0.5  0.69146 0.69497 0.69847 0.70194 0.70540 0.70884 0.71226 0.71566 0.71904 0.72240  0.6  0.72575 0.72907 0.73237 0.73565 0.73891 0.74215 0.74537 0.74857 0.75175 0.75490  0.7  0.75804 0.76115 0.76424 0.76730 0.77035 0.77337 0.77637 0.77935 0.78230 0.78524  0.8  0.78814 0.79103 0.79389 0.79673 0.79955 0.80234 0.80511 0.80785 0.81057 0.81327  0.9  0.81594 0.81859 0.82121 0.82381 0.82639 0.82894 0.83147 0.83398 0.83646 0.83891  1.0  0.84134 0.84375 0.84614 0.84849 0.85083 0.85314 0.85543 0.85769 0.85993 0.86214  1.1  0.86433 0.86650 0.86864 0.87076 0.87286 0.87493 0.87698 0.87900 0.88100 0.88298  1.2  0.88493 0.88686 0.88877 0.89065 0.89251 0.89435 0.89617 0.89796 0.89973 0.90147  1.3  0.90320 0.90490 0.90658 0.90824 0.90988 0.91149 0.91308 0.91466 0.91621 0.91774  1.4  0.91924 0.92073 0.92220 0.92364 0.92507 0.92647 0.92785 0.92922 0.93056 0.93189  1.5  0.93319 0.93448 0.93574 0.93699 0.93822 0.93943 0.94062 0.94179 0.94295 0.94408  1.6  0.94520 0.94630 0.94738 0.94845 0.94950 0.95053 0.95154 0.95254 0.95352 0.95449  1.7  0.95543 0.95637 0.95728 0.95818 0.95907 0.95994 0.96080 0.96164 0.96246 0.96327  1.8  0.96407 0.96485 0.96562 0.96638 0.96712 0.96784 0.96856 0.96926 0.96995 0.97062  1.9  0.97128 0.97193 0.97257 0.97320 0.97381 0.97441 0.97500 0.97558 0.97615 0.97670  2.0  0.97725 0.97778 0.97831 0.97882 0.97932 0.97982 0.98030 0.98077 0.98124 0.98169  2.1  0.98214 0.98257 0.98300 0.98341 0.98382 0.98422 0.98461 0.98500 0.98537 0.98574  2.2  0.98610 0.98645 0.98679 0.98713 0.98745 0.98778 0.98809 0.98840 0.98870 0.98899  2.3  0.98928 0.98956 0.98983 0.99010 0.99036 0.99061 0.99086 0.99111 0.99134 0.99158  2.4  0.99180 0.99202 0.99224 0.99245 0.99266 0.99286 0.99305 0.99324 0.99343 0.99361  2.5  0.99379 0.99396 0.99413 0.99430 0.99446 0.99461 0.99477 0.99492 0.99506 0.99520  2.6  0.99534 0.99547 0.99560 0.99573 0.99585 0.99598 0.99609 0.99621 0.99632 0.99643  2.7  0.99653 0.99664 0.99674 0.99683 0.99693 0.99702 0.99711 0.99720 0.99728 0.99736  2.8  0.99744 0.99752 0.99760 0.99767 0.99774 0.99781 0.99788 0.99795 0.99801 0.99807  2.9  0.99813 0.99819 0.99825 0.99831 0.99836 0.99841 0.99846 0.99851 0.99856 0.99861  3.0  0.99865 0.99869 0.99874 0.99878 0.99882 0.99886 0.99889 0.99893 0.99896 0.99900  3.1  0.99903 0.99906 0.99910 0.99913 0.99916 0.99918 0.99921 0.99924 0.99926 0.99929  3.2  0.99931 0.99934 0.99936 0.99938 0.99940 0.99942 0.99944 0.99946 0.99948 0.99950  3.3  0.99952 0.99953 0.99955 0.99957 0.99958 0.99960 0.99961 0.99962 0.99964 0.99965  3.4  0.99966 0.99968 0.99969 0.99970 0.99971 0.99972 0.99973 0.99974 0.99975 0.99976  3.5  0.99977 0.99978 0.99978 0.99979 0.99980 0.99981 0.99981 0.99982 0.99983 0.99983  3.6  0.99984 0.99985 0.99985 0.99986 0.99986 0.99987 0.99987 0.99988 0.99988 0.99989  3.7  0.99989 0.99990 0.99990 0.99990 0.99991 0.99991 0.99992 0.99992 0.99992 0.99992  3.8  0.99993 0.99993 0.99993 0.99994 0.99994 0.99994 0.99994 0.99995 0.99995 0.99995  3.9  0.99995 0.99995 0.99996 0.99996 0.99996 0.99996 0.99996 0.99996 0.99997 0.99997  4.0  0.99997 0.99997 0.99997 0.99997 0.99997 0.99997 0.99998 0.99998 0.99998 0.99998  z +0.00 +0.01 +0.02 +0.03 +0.04 +0.05 +0.06 +0.07 +0.08 +0.09"},{"location":"topology/intro/","title":"Topology","text":"<p>Consider an ordered pair \\((X, \\tau)\\) consisting of a set \\(X\\) and a set of subsets of \\(X\\), denoted \\(\\tau\\). We call this pair a topological space and say that \\(\\tau\\) is a topology on \\(X\\) if the following hold:</p> <ol> <li>\\(\\emptyset, X \\in \\tau\\)</li> <li>\\(A, B \\in \\tau \\implies A \\cap B \\in \\tau\\)</li> <li>$ i \\in I : S_i \\in \\tau \\implies \\bigcup \\limits_{i \\in I} S_i \\in \\tau $</li> </ol>"},{"location":"vector_spaces/dual_space/","title":"Dual Spaces","text":"<p>Every finite-dimensional vector space \\(V\\) over a field \\(\\mathbb{F}\\) has an associated dual space \\(V^\\star\\), also denoted \\(L(V, \\mathbb{F})\\). Elements of the dual space are sometimes called covectors. In what follows, for clarity, the \"arrow\" vector notation is used only for elements of the vector space \\(V\\) unless where necessary to emphasize the vector nature of elements of the dual space.</p>"},{"location":"vector_spaces/dual_space/#linear-functionals","title":"Linear Functionals","text":"<p>We define a linear functional on \\(V\\) as a map $\\phi: V \\to \\mathbb{F} $:</p> \\[     \\phi(a \\vec u + b \\vec v ) = a \\phi(\\vec u) + b \\phi(\\vec v) \\quad \\text{where} \\quad \\vec u, \\vec v \\in V \\quad a,b \\in \\mathbb{F} \\] <p>By this definition the linear functionals are also vector space homomorphisms, where the field \\(\\mathbb{F}\\) is viewed as a one-dimensional vector space; the dual space is also denoted \\(Hom(V, \\mathbb{F})\\) for this reason. These linear functionals are themselves vectors and form the dual space; they can be added and multiplied by scalars from \\(\\mathbb{F}\\) to form new linear functionals:</p> \\[     \\phi(\\vec u) + \\omega(\\vec u) = (\\phi + \\omega)(\\vec u) \\] \\[     a \\phi (\\vec u) = (a \\phi)(\\vec u)  \\]"},{"location":"vector_spaces/dual_space/#dual-basis","title":"Dual Basis","text":"<p>For a finite dimensional vector space \\(V\\), let its basis vectors be \\(\\{ e_1, \\dots, e_n \\}\\) and define \\(n\\) linear functionals \\(\\{ \\epsilon_1, \\dots, \\epsilon_n \\}\\) using the Kronecker delta by</p> \\[     \\epsilon_i (e_k) = \\delta_{ik}  \\] <p>These linear functionals form a basis for \\(V^\\star\\) known as the dual basis, where \\(dim(V) = dim(V^\\star)\\).</p>"},{"location":"vector_spaces/dual_space/#proof","title":"Proof","text":"<p>To show that these vectors form a basis it is sufficient to show that they are linearly independent, that is, we must show</p> \\[     \\sum_{i=1}^n a_i \\epsilon_i = 0 \\quad \\implies \\quad a_i = 0, \\forall a_i \\in \\mathbb{F} \\] <p>As the basis vectors are linear functionals, we can apply the vector above to any basis vector \\(e_k \\in V\\):</p> \\[     \\sum_{i=1}^n a_i \\epsilon_i(e_k)  = 0 \\] <p>By the definition of the dual basis vectors, all terms are zero except for when \\(i = k\\)</p> \\[     \\begin{align*}         a_k \\epsilon_k(e_k) = 0 \\\\         a_k .1  = 0 \\\\         a_k = 0     \\end{align*} \\]"},{"location":"vector_spaces/dual_space/#covectors-as-row-vectors","title":"Covectors as Row Vectors","text":"<p>In matrix notation, elements of the dual space \\(V^\\star\\) can be regarded as row vectors, in contrast to the standard representation of finite dimensional vectors as column vectors. For a vector \\(\\vec v \\in V\\) and linear functional (covector) \\(\\vec g \\in V^\\star\\):</p> \\[     \\begin{align*}         &amp; \\vec w = \\sum_{i=1}^n w_i e_i \\quad w_i \\in \\mathbb{F} \\\\         &amp; \\vec g = \\sum_{i=1}^n g_i \\epsilon_i \\quad g_i \\in \\mathbb{F} \\\\         &amp; g(\\vec w) = \\sum_{i=1}^n w_i g(e_i) = \\sum_{i=1}^n w_i g_i \\\\     \\end{align*} \\] <p>This can be represented as the product of a row and column matrix:</p> \\[     \\begin{bmatrix} g_1 &amp; \\dots &amp; g_n \\end{bmatrix}     \\begin{bmatrix} w_1  \\\\\\ \\vdots \\\\\\ w_n \\end{bmatrix} \\]"},{"location":"vector_spaces/dual_space/#visualization","title":"Visualization","text":"<p>Linear functionals are vectors in their own right in \\(V^\\star\\) but we can also visualize them in \\(V\\). Recall the equation for a plane in \\(\\mathbb{R}^3\\), where \\((a,b,c)\\) are the components in the \\((\\hat x, \\hat y, \\hat z)\\) directions of the vector normal to the plane:</p> \\[     ax + by + cz = d  \\] <p>Now consider all vectors \\(\\vec v \\in \\mathbb{R}^3\\) for which the linear functional \\(g\\) is equal to some constant \\(\\alpha\\).  This equation is identical in form to the equation of a plane:</p> \\[     g(\\vec v) = g_1 v_1 + g_2 v_2 + g_3 v_3 = \\alpha \\] <p>Therefore, a linear functional can be visualized in \\(V\\) as the set of planes perpendicular to the normal vector whose components are given by \\(g_i\\). This can clearly be extended to hyperplanes in higher dimensions.</p> <p></p>"},{"location":"vector_spaces/dual_space/#dual-of-the-dual","title":"Dual of the Dual","text":"<p>As \\(V^\\star\\) is itself a vector space, we can consider the dual \\(V^{**}\\) of this dual space. For finite dimensional vector spaces, the dualing process stops at the first dual; the dual of the dual space is the original vector space \\(V\\).</p> <p>Similar to how the linear functionals were defined for \\(V\\), consider a map \\(\\bar\\omega: V^\\star \\to \\mathbb{F}\\) that acts on the dual space. This maps takes a linear functional \\(g\\) and maps it to an element of the field \\(\\mathbb{F}\\), however, there will be some vector \\(\\vec v\\) that the linear functional \\(g\\) also maps to the same value in \\(\\mathbb{F}\\):</p> \\[     \\bar\\omega(g) = g(\\vec v) \\quad \\forall g \\in V^\\star \\] <p>The map \\(\\bar\\omega\\) is a linear functional in its own right. For \\(g,h \\in V^\\star\\) and \\(\\alpha,\\beta \\in \\mathbb{F}\\):</p> \\[       \\begin{align*}         \\bar{\\omega}(\\alpha g + \\beta h) = (\\alpha g + \\beta h)(\\vec v) \\\\         = \\alpha g(\\vec v) + \\beta h(\\vec v) \\\\         = \\alpha \\bar{\\omega}(g) + \\beta \\bar{\\omega}(h) \\\\     \\end{align*} \\] <p>As there is a way to associate every \\(v \\in V\\) with an \\(\\bar{\\omega} \\in V^{\\star \\star}\\), this implies the existence of a map \\(\\rho: V \\to V^{\\star \\star}\\):</p> \\[     \\bar{\\omega}(g) = g(\\vec v) \\implies \\rho(\\vec v) = \\bar{\\omega} \\] <p>The map \\(\\rho\\) is linear:</p> \\[       \\begin{align*}         \\rho(a \\vec{u} + b \\vec{v})(g) = \\bar{\\sigma}(g) \\\\         = g(a \\vec{u} + b \\vec{v}) \\\\         = a g(\\vec{u}) + b g(\\vec{v}) \\\\         = a \\rho(\\vec{u})(g) + b \\rho(\\vec{v})(g) \\\\     \\end{align*} \\] <p>Since this is true for arbitrary \\(g\\) we have \\(\\rho(a \\vec{u} + b \\vec{v}) = a \\rho(\\vec{u}) + b \\rho(\\vec{v})\\), proving linearity.</p>"},{"location":"vector_spaces/dual_space/#basis","title":"Basis","text":"<p>The linear functionals \\(\\rho(e_i)\\) form a basis for \\(V^{**}\\), where \\(e_i\\) are the basis for \\(V\\).</p>"},{"location":"vector_spaces/dual_space/#proof_1","title":"Proof","text":"<p>The proof proceeds as above where we must show the following:</p> \\[     \\sum_{i=1}^n \\bar{a}_i \\rho(e_i) = 0 \\quad \\implies \\quad \\bar{a_i} = 0, \\forall \\bar{a_i} \\in \\mathbb{F} \\] <p>We can apply the linear functional above above to any basis vector \\(\\epsilon_k \\in V^{\\star}\\):</p> \\[     \\sum_{i=1}^n \\bar{a}_i \\rho(e_i)(\\epsilon_k) = 0 \\] \\[     \\begin{align*}         \\rho(e_i)(\\epsilon_k) = \\epsilon_k(e_i) = \\delta_{ik} \\\\         \\bar{a}_k \\rho(e_k)(\\epsilon_k) = 0 \\\\         a_k 1 = 0 \\\\         a_k = 0     \\end{align*} \\]"},{"location":"vector_spaces/dual_space/#natural-isomorphism","title":"Natural Isomorphism:","text":"<p>The map \\(\\rho\\) is onto as every \\(\\bar{\\omega} \\in V^{\\star \\star}\\) is mapped to by some vector in \\(V\\), as we can see by the linearity of \\(\\rho\\):</p> \\[     \\bar{\\omega} = \\sum_{i=1}^n \\bar{a}_i \\rho(e_i) = \\sum_{i=1}^n \\rho(\\bar{a}_i e_i) = \\rho(\\sum_{i=1}^n \\bar{a}_i e_i) \\quad \\bar{a}_i \\in \\mathbb{F} \\] <p>The map \\(\\rho\\) is also one-to-one because by the definition of a basis each vector \\(\\sum_{i=1}^n \\bar{a}_i e_i\\) is unique. Therefore, the map \\(\\rho\\) is an isomorphism between \\(V\\) and \\(V^{\\star \\star}\\). Note that the relation \\(\\bar{\\omega}(g) = g(\\vec{v})\\) makes no reference to a basis so we call \\(V \\cong V^{\\star \\star}\\) a natural isomorphism; there is no ambiguity in writing \\(\\vec{v}(g) = g(\\vec{v})\\).</p>"},{"location":"vector_spaces/hilbert_space/","title":"Hilbert space","text":""},{"location":"vector_spaces/hilbert_space/#hilbert-space","title":"Hilbert Space","text":""},{"location":"vector_spaces/hilbert_space/#inner-product-of-hilbert-space-tensor-products","title":"Inner Product of Hilbert Space Tensor Products","text":"<p>For Hilbert spaces \\(H_1\\) and \\(H_2\\), and vectors \\(v_1, v_2 \\in H_1\\), \\(w_1, w_2 \\in H_2\\), the inner product and tensor product are related by the following:</p> \\[     \\langle v_1 \\otimes v_2 , w_1 \\otimes w_2 \\rangle = \\langle v_1 , w_1 \\rangle \\langle v_2 , w_2 \\rangle \\]"}]}